{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fb92820",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-16T11:39:17.087415Z",
     "iopub.status.busy": "2023-12-16T11:39:17.086492Z",
     "iopub.status.idle": "2023-12-16T11:39:30.167197Z",
     "shell.execute_reply": "2023-12-16T11:39:30.166245Z"
    },
    "papermill": {
     "duration": 13.096876,
     "end_time": "2023-12-16T11:39:30.169770",
     "exception": false,
     "start_time": "2023-12-16T11:39:17.072894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchgeometry\r\n",
      "  Downloading torchgeometry-0.1.2-py2.py3-none-any.whl (42 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.0.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\r\n",
      "Installing collected packages: torchgeometry\r\n",
      "Successfully installed torchgeometry-0.1.2\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install torchgeometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6a781e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:39:30.197702Z",
     "iopub.status.busy": "2023-12-16T11:39:30.197026Z",
     "iopub.status.idle": "2023-12-16T11:39:41.831161Z",
     "shell.execute_reply": "2023-12-16T11:39:41.830140Z"
    },
    "papermill": {
     "duration": 11.650996,
     "end_time": "2023-12-16T11:39:41.833617",
     "exception": false,
     "start_time": "2023-12-16T11:39:30.182621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\r\n",
      "Version: 2.0.0\r\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\r\n",
      "Home-page: https://pytorch.org/\r\n",
      "Author: PyTorch Team\r\n",
      "Author-email: packages@pytorch.org\r\n",
      "License: BSD-3\r\n",
      "Location: /opt/conda/lib/python3.10/site-packages\r\n",
      "Requires: filelock, jinja2, networkx, sympy, typing-extensions\r\n",
      "Required-by: accelerate, catalyst, easyocr, fastai, kornia, pytorch-ignite, pytorch-lightning, stable-baselines3, timm, torchaudio, torchdata, torchgeometry, torchmetrics, torchtext, torchvision\r\n"
     ]
    }
   ],
   "source": [
    "!pip show torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e1534f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:39:41.860289Z",
     "iopub.status.busy": "2023-12-16T11:39:41.859894Z",
     "iopub.status.idle": "2023-12-16T11:39:52.312293Z",
     "shell.execute_reply": "2023-12-16T11:39:52.311452Z"
    },
    "papermill": {
     "duration": 10.469022,
     "end_time": "2023-12-16T11:39:52.315015",
     "exception": false,
     "start_time": "2023-12-16T11:39:41.845993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from torchgeometry.losses import one_hot\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import Resize, PILToTensor, ToPILImage, Compose, InterpolationMode\n",
    "from collections import OrderedDict\n",
    "import wandb\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import glob\n",
    "import multiprocessing.pool as mpp\n",
    "import multiprocessing as mp\n",
    "import argparse\n",
    "import torch\n",
    "import albumentations as albu\n",
    "from torchvision.transforms import (Pad, ColorJitter, Resize, FiveCrop, RandomResizedCrop,\n",
    "                                    RandomHorizontalFlip, RandomRotation, RandomVerticalFlip)\n",
    "import random\n",
    "import math\n",
    "import numbers\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion\n",
    "from scipy.ndimage import maximum_filter\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "# from pytorch_lightning.callbacks import Model\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811f37d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:39:52.342875Z",
     "iopub.status.busy": "2023-12-16T11:39:52.342378Z",
     "iopub.status.idle": "2023-12-16T11:39:52.358325Z",
     "shell.execute_reply": "2023-12-16T11:39:52.357397Z"
    },
    "papermill": {
     "duration": 0.032657,
     "end_time": "2023-12-16T11:39:52.360422",
     "exception": false,
     "start_time": "2023-12-16T11:39:52.327765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622c9a6e",
   "metadata": {
    "papermill": {
     "duration": 0.011999,
     "end_time": "2023-12-16T11:39:52.385378",
     "exception": false,
     "start_time": "2023-12-16T11:39:52.373379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857c2509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:39:52.411626Z",
     "iopub.status.busy": "2023-12-16T11:39:52.410946Z",
     "iopub.status.idle": "2023-12-16T11:39:52.416610Z",
     "shell.execute_reply": "2023-12-16T11:39:52.415693Z"
    },
    "papermill": {
     "duration": 0.021196,
     "end_time": "2023-12-16T11:39:52.418574",
     "exception": false,
     "start_time": "2023-12-16T11:39:52.397378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 6\n",
    "\n",
    "# Number of epoch\n",
    "epochs = 25\n",
    "\n",
    "# Hyperparameters for training \n",
    "learning_rate = 1e-03\n",
    "batch_size = 16\n",
    "display_step = 2\n",
    "\n",
    "# Model path\n",
    "checkpoint_path = '/kaggle/working/unetplusplus_tune.pth'\n",
    "pretrained_path = \"/kaggle/input/model2/unet_model.pth\"\n",
    "# Initialize lists to keep track of loss and accuracy\n",
    "loss_epoch_array = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "valid_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b9dcca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:39:52.443907Z",
     "iopub.status.busy": "2023-12-16T11:39:52.443619Z",
     "iopub.status.idle": "2023-12-16T11:39:52.666382Z",
     "shell.execute_reply": "2023-12-16T11:39:52.665436Z"
    },
    "papermill": {
     "duration": 0.238271,
     "end_time": "2023-12-16T11:39:52.668772",
     "exception": false,
     "start_time": "2023-12-16T11:39:52.430501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(42)\n",
    "\n",
    "ImSurf = np.array([255, 255, 255])  # label 0\n",
    "Building = np.array([255, 0, 0]) # label 1\n",
    "LowVeg = np.array([255, 255, 0]) # label 2\n",
    "Tree = np.array([0, 255, 0]) # label 3\n",
    "Car = np.array([0, 255, 255]) # label 4\n",
    "Clutter = np.array([0, 0, 255]) # label 5\n",
    "Boundary = np.array([0, 0, 0]) # label 6\n",
    "num_classes = 6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pv2rgb(mask):\n",
    "    h, w = mask.shape[0], mask.shape[1]\n",
    "    mask_rgb = np.zeros(shape=(h, w, 3), dtype=np.uint8)\n",
    "    mask_convert = mask[np.newaxis, :, :]\n",
    "    mask_rgb[np.all(mask_convert == 3, axis=0)] = [0, 255, 0]\n",
    "    mask_rgb[np.all(mask_convert == 0, axis=0)] = [255, 255, 255]\n",
    "    mask_rgb[np.all(mask_convert == 1, axis=0)] = [255, 0, 0]\n",
    "    mask_rgb[np.all(mask_convert == 2, axis=0)] = [255, 255, 0]\n",
    "    mask_rgb[np.all(mask_convert == 4, axis=0)] = [0, 204, 255]\n",
    "    mask_rgb[np.all(mask_convert == 5, axis=0)] = [0, 0, 255]\n",
    "    return mask_rgb\n",
    "def label2rgb(mask):\n",
    "    h, w = mask.shape[0], mask.shape[1]\n",
    "    mask_rgb = np.zeros(shape=(h, w, 3), dtype=np.uint8)\n",
    "    mask_convert = mask[np.newaxis, :, :]\n",
    "    mask_rgb[np.all(mask_convert == 3, axis=0)] = [0, 255, 0]\n",
    "    mask_rgb[np.all(mask_convert == 0, axis=0)] = [255, 255, 255]\n",
    "    mask_rgb[np.all(mask_convert == 1, axis=0)] = [255, 0, 0]\n",
    "    mask_rgb[np.all(mask_convert == 2, axis=0)] = [255, 255, 0]\n",
    "    mask_rgb[np.all(mask_convert == 4, axis=0)] = [0, 204, 255]\n",
    "    mask_rgb[np.all(mask_convert == 5, axis=0)] = [0, 0, 255]\n",
    "    return mask_rgb\n",
    "\n",
    "\n",
    "\n",
    "def car_color_replace(mask):\n",
    "    mask = cv2.cvtColor(np.array(mask.copy()), cv2.COLOR_RGB2BGR)\n",
    "    mask[np.all(mask == [0, 255, 255], axis=-1)] = [0, 204, 255]\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def rgb_to_2D_label(_label):\n",
    "    _label = _label.transpose(2, 0, 1)\n",
    "    label_seg = np.zeros(_label.shape[1:], dtype=np.uint8)\n",
    "    label_seg[np.all(_label.transpose([1, 2, 0]) == ImSurf, axis=-1)] = 0\n",
    "    label_seg[np.all(_label.transpose([1, 2, 0]) == Building, axis=-1)] = 1\n",
    "    label_seg[np.all(_label.transpose([1, 2, 0]) == LowVeg, axis=-1)] = 2\n",
    "    label_seg[np.all(_label.transpose([1, 2, 0]) == Tree, axis=-1)] = 3\n",
    "    label_seg[np.all(_label.transpose([1, 2, 0]) == Car, axis=-1)] = 4\n",
    "    label_seg[np.all(_label.transpose([1, 2, 0]) == Clutter, axis=-1)] = 5\n",
    "    label_seg[np.all(_label.transpose([1, 2, 0]) == Boundary, axis=-1)] = 6\n",
    "    return label_seg\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5f0a9",
   "metadata": {
    "papermill": {
     "duration": 0.011928,
     "end_time": "2023-12-16T11:39:52.693019",
     "exception": false,
     "start_time": "2023-12-16T11:39:52.681091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec5be87",
   "metadata": {
    "papermill": {
     "duration": 0.012277,
     "end_time": "2023-12-16T11:39:52.717562",
     "exception": false,
     "start_time": "2023-12-16T11:39:52.705285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3ea3b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:39:52.743683Z",
     "iopub.status.busy": "2023-12-16T11:39:52.743364Z",
     "iopub.status.idle": "2023-12-16T11:39:52.772710Z",
     "shell.execute_reply": "2023-12-16T11:39:52.771942Z"
    },
    "papermill": {
     "duration": 0.045158,
     "end_time": "2023-12-16T11:39:52.774803",
     "exception": false,
     "start_time": "2023-12-16T11:39:52.729645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLASSES = ('ImSurf', 'Building', 'LowVeg', 'Tree', 'Car', 'Clutter')\n",
    "class_label={0:'ImSurf', 1:'Building',2: 'LowVeg', 3:'Tree', 4:'Car',5: 'Clutter'}\n",
    "PALETTE = [[255, 255, 255], [0, 0, 255], [0, 255, 255], [0, 255, 0], [255, 204, 0], [255, 0, 0]]\n",
    "\n",
    "ORIGIN_IMG_SIZE = (256, 256)\n",
    "INPUT_IMG_SIZE = (256, 256)\n",
    "TEST_IMG_SIZE = (256, 256)\n",
    "\n",
    "def get_training_transform():\n",
    "    train_transform = [\n",
    "        # albu.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=0.15),\n",
    "        # albu.RandomRotate90(p=0.25),\n",
    "        albu.Normalize()\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "def get_val_transform():\n",
    "    val_transform = [\n",
    "        albu.RandomRotate90(p=0.5),\n",
    "        albu.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, p=0.5),\n",
    "        albu.Normalize()\n",
    "    ]\n",
    "    return albu.Compose(val_transform)\n",
    "\n",
    "\n",
    "def val_aug(img, mask):\n",
    "    img, mask = np.array(img), np.array(mask)\n",
    "    aug = get_val_transform()(image=img.copy(), mask=mask.copy())\n",
    "    img, mask = aug['image'], aug['mask']\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "class PotsdamDataset(Dataset):\n",
    "    def __init__(self, data_root='/kaggle/input/deep-data-potsdam-vaihingen/Deep_data_segmentation/Split/Potsdam/', mode='val', img_dir='Image', mask_dir='Label/',\n",
    "                 img_suffix='.tif', mask_suffix='.png', transform=val_aug, mosaic_ratio=0.0,\n",
    "                 img_size=ORIGIN_IMG_SIZE):\n",
    "        self.data_root = data_root\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_suffix = img_suffix\n",
    "        self.mask_suffix = mask_suffix\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.mosaic_ratio = mosaic_ratio\n",
    "        self.img_size = img_size\n",
    "        self.img_ids = self.get_img_ids(self.data_root, self.img_dir, self.mask_dir)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        p_ratio = random.random()\n",
    "        if p_ratio > self.mosaic_ratio or self.mode == 'val' or self.mode == 'test':\n",
    "            img, mask = self.load_img_and_mask(index)\n",
    "            if self.transform:\n",
    "                img, mask = self.transform(img, mask)\n",
    "        else:\n",
    "            img, mask = self.load_mosaic_img_and_mask(index)\n",
    "            if self.transform:\n",
    "                img, mask = self.transform(img, mask)\n",
    "\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        img_id = self.img_ids[index]\n",
    "        results = dict(img_id=img_id, img=img, gt_semantic_seg=mask)\n",
    "        return results\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def get_img_ids(self, data_root, img_dir, mask_dir):\n",
    "        img_filename_list = os.listdir(osp.join(data_root, img_dir))\n",
    "        mask_filename_list = os.listdir(osp.join(data_root, mask_dir))\n",
    "        assert len(img_filename_list) == len(mask_filename_list)\n",
    "        img_ids = [str(id.split('.')[0]) for id in mask_filename_list]\n",
    "        return img_ids\n",
    "\n",
    "    def load_img_and_mask(self, index):\n",
    "        img_id = self.img_ids[index]\n",
    "        img_name = osp.join(self.data_root, self.img_dir, img_id + self.img_suffix)\n",
    "        mask_name = osp.join(self.data_root, self.mask_dir, img_id + self.mask_suffix)\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        mask = Image.open(mask_name).convert('L')\n",
    "        return img, mask\n",
    "\n",
    "    def load_mosaic_img_and_mask(self, index):\n",
    "        indexes = [index] + [random.randint(0, len(self.img_ids) - 1) for _ in range(3)]\n",
    "        img_a, mask_a = self.load_img_and_mask(indexes[0])\n",
    "        img_b, mask_b = self.load_img_and_mask(indexes[1])\n",
    "        img_c, mask_c = self.load_img_and_mask(indexes[2])\n",
    "        img_d, mask_d = self.load_img_and_mask(indexes[3])\n",
    "\n",
    "        img_a, mask_a = np.array(img_a), np.array(mask_a)\n",
    "        img_b, mask_b = np.array(img_b), np.array(mask_b)\n",
    "        img_c, mask_c = np.array(img_c), np.array(mask_c)\n",
    "        img_d, mask_d = np.array(img_d), np.array(mask_d)\n",
    "\n",
    "        w = self.img_size[1]\n",
    "        h = self.img_size[0]\n",
    "\n",
    "        start_x = w // 4\n",
    "        strat_y = h // 4\n",
    "        # The coordinates of the splice center\n",
    "        offset_x = random.randint(start_x, (w - start_x))\n",
    "        offset_y = random.randint(strat_y, (h - strat_y))\n",
    "\n",
    "        crop_size_a = (offset_x, offset_y)\n",
    "        crop_size_b = (w - offset_x, offset_y)\n",
    "        crop_size_c = (offset_x, h - offset_y)\n",
    "        crop_size_d = (w - offset_x, h - offset_y)\n",
    "\n",
    "        random_crop_a = albu.RandomCrop(width=crop_size_a[0], height=crop_size_a[1])\n",
    "        random_crop_b = albu.RandomCrop(width=crop_size_b[0], height=crop_size_b[1])\n",
    "        random_crop_c = albu.RandomCrop(width=crop_size_c[0], height=crop_size_c[1])\n",
    "        random_crop_d = albu.RandomCrop(width=crop_size_d[0], height=crop_size_d[1])\n",
    "\n",
    "        croped_a = random_crop_a(image=img_a.copy(), mask=mask_a.copy())\n",
    "        croped_b = random_crop_b(image=img_b.copy(), mask=mask_b.copy())\n",
    "        croped_c = random_crop_c(image=img_c.copy(), mask=mask_c.copy())\n",
    "        croped_d = random_crop_d(image=img_d.copy(), mask=mask_d.copy())\n",
    "\n",
    "        img_crop_a, mask_crop_a = croped_a['image'], croped_a['mask']\n",
    "        img_crop_b, mask_crop_b = croped_b['image'], croped_b['mask']\n",
    "        img_crop_c, mask_crop_c = croped_c['image'], croped_c['mask']\n",
    "        img_crop_d, mask_crop_d = croped_d['image'], croped_d['mask']\n",
    "\n",
    "        top = np.concatenate((img_crop_a, img_crop_b), axis=1)\n",
    "        bottom = np.concatenate((img_crop_c, img_crop_d), axis=1)\n",
    "        img = np.concatenate((top, bottom), axis=0)\n",
    "\n",
    "        top_mask = np.concatenate((mask_crop_a, mask_crop_b), axis=1)\n",
    "        bottom_mask = np.concatenate((mask_crop_c, mask_crop_d), axis=1)\n",
    "        mask = np.concatenate((top_mask, bottom_mask), axis=0)\n",
    "        mask = np.ascontiguousarray(mask)\n",
    "        img = np.ascontiguousarray(img)\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d784a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:39:52.801163Z",
     "iopub.status.busy": "2023-12-16T11:39:52.800571Z",
     "iopub.status.idle": "2023-12-16T11:39:54.020800Z",
     "shell.execute_reply": "2023-12-16T11:39:54.019774Z"
    },
    "papermill": {
     "duration": 1.236288,
     "end_time": "2023-12-16T11:39:54.023300",
     "exception": false,
     "start_time": "2023-12-16T11:39:52.787012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = PotsdamDataset(data_root='/kaggle/input/deep-data-potsdam-vaihingen/Deep_data_segmentation/Split/Potsdam/', mode='train',\n",
    "                               mosaic_ratio=0.25, transform=val_aug)\n",
    "\n",
    "train_size = 0.35\n",
    "valid_size = 0.65\n",
    "dumb1 = 0.15\n",
    "dumb2 = 0.85\n",
    "train_length = round(train_size * len(train_dataset))\n",
    "valid_length = round(valid_size * len(train_dataset))\n",
    "train_set, dumb0 = random_split(train_dataset, [train_length, valid_length])\n",
    "val_set, xxx = random_split(dumb0, [dumb1, dumb2])\n",
    "\n",
    "\n",
    "test_dataset = PotsdamDataset(data_root='/kaggle/input/deep-data-potsdam-vaihingen/Deep_data_segmentation/Split/Potsdam/Test',\n",
    "                              transform=val_aug)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=0,\n",
    "                          pin_memory=False,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True\n",
    "                         )\n",
    "\n",
    "val_loader = DataLoader(dataset=val_set,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=2,\n",
    "                        shuffle=False,\n",
    "                        pin_memory=True,\n",
    "                        drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b5573",
   "metadata": {
    "papermill": {
     "duration": 0.012303,
     "end_time": "2023-12-16T11:39:54.048156",
     "exception": false,
     "start_time": "2023-12-16T11:39:54.035853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef8eae8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:39:54.074833Z",
     "iopub.status.busy": "2023-12-16T11:39:54.074093Z",
     "iopub.status.idle": "2023-12-16T11:39:54.092111Z",
     "shell.execute_reply": "2023-12-16T11:39:54.091257Z"
    },
    "papermill": {
     "duration": 0.033818,
     "end_time": "2023-12-16T11:39:54.094305",
     "exception": false,
     "start_time": "2023-12-16T11:39:54.060487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, num_class):\n",
    "        self.num_class = num_class\n",
    "        self.confusion_matrix = np.zeros((self.num_class,) * 2)\n",
    "        self.eps = 1e-8\n",
    "\n",
    "    def get_tp_fp_tn_fn(self):\n",
    "        tp = np.diag(self.confusion_matrix)\n",
    "        fp = self.confusion_matrix.sum(axis=0) - np.diag(self.confusion_matrix)\n",
    "        fn = self.confusion_matrix.sum(axis=1) - np.diag(self.confusion_matrix)\n",
    "        tn = np.diag(self.confusion_matrix).sum() - np.diag(self.confusion_matrix)\n",
    "        return tp, fp, tn, fn\n",
    "\n",
    "    def Precision(self):\n",
    "        tp, fp, tn, fn = self.get_tp_fp_tn_fn()\n",
    "        precision = tp / (tp + fp)\n",
    "        return precision\n",
    "\n",
    "    def Recall(self):\n",
    "        tp, fp, tn, fn = self.get_tp_fp_tn_fn()\n",
    "        recall = tp / (tp + fn)\n",
    "        return recall\n",
    "\n",
    "    def F1(self):\n",
    "        tp, fp, tn, fn = self.get_tp_fp_tn_fn()\n",
    "        Precision = tp / (tp + fp)\n",
    "        Recall = tp / (tp + fn)\n",
    "        F1 = (2.0 * Precision * Recall) / (Precision + Recall)\n",
    "        return F1\n",
    "\n",
    "    def OA(self):\n",
    "        OA = np.diag(self.confusion_matrix).sum() / (self.confusion_matrix.sum() + self.eps)\n",
    "        return OA\n",
    "\n",
    "    def Intersection_over_Union(self):\n",
    "        tp, fp, tn, fn = self.get_tp_fp_tn_fn()\n",
    "        IoU = tp / (tp + fn + fp)\n",
    "        return IoU\n",
    "\n",
    "    def Dice(self):\n",
    "        tp, fp, tn, fn = self.get_tp_fp_tn_fn()\n",
    "        Dice = 2 * tp / ((tp + fp) + (tp + fn))\n",
    "        return Dice\n",
    "\n",
    "    def Pixel_Accuracy_Class(self):\n",
    "        #         TP                                  TP+FP\n",
    "        Acc = np.diag(self.confusion_matrix) / (self.confusion_matrix.sum(axis=0) + self.eps)\n",
    "        return Acc\n",
    "\n",
    "    def Frequency_Weighted_Intersection_over_Union(self):\n",
    "        freq = np.sum(self.confusion_matrix, axis=1) / (np.sum(self.confusion_matrix) + self.eps)\n",
    "        iou = self.Intersection_over_Union()\n",
    "        FWIoU = (freq[freq > 0] * iou[freq > 0]).sum()\n",
    "        return FWIoU\n",
    "\n",
    "    def _generate_matrix(self, gt_image, pre_image):\n",
    "        mask = (gt_image >= 0) & (gt_image < self.num_class)\n",
    "        label = self.num_class * gt_image[mask].astype('int') + pre_image[mask]\n",
    "        count = np.bincount(label, minlength=self.num_class ** 2)\n",
    "        confusion_matrix = count.reshape(self.num_class, self.num_class)\n",
    "        return confusion_matrix\n",
    "\n",
    "    def add_batch(self, gt_image, pre_image):\n",
    "        assert gt_image.shape == pre_image.shape, 'pre_image shape {}, gt_image shape {}'.format(pre_image.shape,\n",
    "                                                                                                 gt_image.shape)\n",
    "        self.confusion_matrix += self._generate_matrix(gt_image, pre_image)\n",
    "\n",
    "    def reset(self):\n",
    "        self.confusion_matrix = np.zeros((self.num_class,) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26af5f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:39:54.119892Z",
     "iopub.status.busy": "2023-12-16T11:39:54.119174Z",
     "iopub.status.idle": "2023-12-16T11:40:06.151957Z",
     "shell.execute_reply": "2023-12-16T11:40:06.150946Z"
    },
    "papermill": {
     "duration": 12.048292,
     "end_time": "2023-12-16T11:40:06.154440",
     "exception": false,
     "start_time": "2023-12-16T11:39:54.106148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\r\n",
      "  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\r\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: einops\r\n",
      "Successfully installed einops-0.7.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d89b09",
   "metadata": {
    "papermill": {
     "duration": 0.012384,
     "end_time": "2023-12-16T11:40:06.227794",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.215410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f935f",
   "metadata": {
    "papermill": {
     "duration": 0.01242,
     "end_time": "2023-12-16T11:40:06.252745",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.240325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df78fedc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:06.281129Z",
     "iopub.status.busy": "2023-12-16T11:40:06.280028Z",
     "iopub.status.idle": "2023-12-16T11:40:06.285053Z",
     "shell.execute_reply": "2023-12-16T11:40:06.284294Z"
    },
    "papermill": {
     "duration": 0.021502,
     "end_time": "2023-12-16T11:40:06.286984",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.265482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Instantiate your UNet model\n",
    "# model = A2FPN()\n",
    "\n",
    "\n",
    "# # Print the shape of the outputmodel = UNet(n_class=6)\n",
    "\n",
    "# # Create a dummy batch with random images\n",
    "# dummy_batch_size = 4  # Choose your batch size\n",
    "# dummy_input_batch = torch.randn(dummy_batch_size, 3, 256, 256)  # Batch size, 3 channels, 256x256\n",
    "\n",
    "# # Forward pass\n",
    "# output_batch = model(dummy_input_batch)\n",
    "\n",
    "# # Print the shape of the output batch\n",
    "\n",
    "# print(\"Output batch shape:\", output_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552390ff",
   "metadata": {
    "papermill": {
     "duration": 0.012316,
     "end_time": "2023-12-16T11:40:06.311800",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.299484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1291afbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:06.338509Z",
     "iopub.status.busy": "2023-12-16T11:40:06.337667Z",
     "iopub.status.idle": "2023-12-16T11:40:06.348221Z",
     "shell.execute_reply": "2023-12-16T11:40:06.347291Z"
    },
    "papermill": {
     "duration": 0.025912,
     "end_time": "2023-12-16T11:40:06.350182",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.324270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_smoothed_nll_loss(\n",
    "    lprobs: torch.Tensor, target: torch.Tensor, epsilon: float, ignore_index=None, reduction=\"mean\", dim=-1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    Source: https://github.com/pytorch/fairseq/blob/master/fairseq/criterions/label_smoothed_cross_entropy.py\n",
    "\n",
    "    :param lprobs: Log-probabilities of predictions (e.g after log_softmax)\n",
    "    :param target:\n",
    "    :param epsilon:\n",
    "    :param ignore_index:\n",
    "    :param reduction:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if target.dim() == lprobs.dim() - 1:\n",
    "        target = target.unsqueeze(dim)\n",
    "\n",
    "    if ignore_index is not None:\n",
    "        pad_mask = target.eq(ignore_index)\n",
    "        target = target.masked_fill(pad_mask, 0)\n",
    "        nll_loss = -lprobs.gather(dim=dim, index=target)\n",
    "        smooth_loss = -lprobs.sum(dim=dim, keepdim=True)\n",
    "\n",
    "        # nll_loss.masked_fill_(pad_mask, 0.0)\n",
    "        # smooth_loss.masked_fill_(pad_mask, 0.0)\n",
    "        nll_loss = nll_loss.masked_fill(pad_mask, 0.0)\n",
    "        smooth_loss = smooth_loss.masked_fill(pad_mask, 0.0)\n",
    "    else:\n",
    "        nll_loss = -lprobs.gather(dim=dim, index=target)\n",
    "        smooth_loss = -lprobs.sum(dim=dim, keepdim=True)\n",
    "\n",
    "        nll_loss = nll_loss.squeeze(dim)\n",
    "        smooth_loss = smooth_loss.squeeze(dim)\n",
    "\n",
    "    if reduction == \"sum\":\n",
    "        nll_loss = nll_loss.sum()\n",
    "        smooth_loss = smooth_loss.sum()\n",
    "    if reduction == \"mean\":\n",
    "        nll_loss = nll_loss.mean()\n",
    "        smooth_loss = smooth_loss.mean()\n",
    "\n",
    "    eps_i = epsilon / lprobs.size(dim)\n",
    "    loss = (1.0 - epsilon) * nll_loss + eps_i * smooth_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0dfc80f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:06.377227Z",
     "iopub.status.busy": "2023-12-16T11:40:06.376917Z",
     "iopub.status.idle": "2023-12-16T11:40:06.406713Z",
     "shell.execute_reply": "2023-12-16T11:40:06.405823Z"
    },
    "papermill": {
     "duration": 0.045577,
     "end_time": "2023-12-16T11:40:06.408803",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.363226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "__all__ = [\"SoftCrossEntropyLoss\"]\n",
    "from typing import Optional\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from typing import List\n",
    "class SoftCrossEntropyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Drop-in replacement for nn.CrossEntropyLoss with few additions:\n",
    "    - Support of label smoothing\n",
    "    \"\"\"\n",
    "\n",
    "    __constants__ = [\"reduction\", \"ignore_index\", \"smooth_factor\"]\n",
    "\n",
    "    def __init__(self, reduction: str = \"mean\", smooth_factor: float = 0.0, ignore_index: Optional[int] = -100, dim=1):\n",
    "        super().__init__()\n",
    "        self.smooth_factor = smooth_factor\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        log_prob = F.log_softmax(input, dim=self.dim)\n",
    "        pad_mask = target.eq(self.ignore_index)\n",
    "        target = target.masked_fill(pad_mask, 0)\n",
    "        log_prob = log_prob.masked_fill(pad_mask.unsqueeze(1), 0)\n",
    "        return label_smoothed_nll_loss(\n",
    "            log_prob,\n",
    "            target,\n",
    "            epsilon=self.smooth_factor,\n",
    "            ignore_index=self.ignore_index,\n",
    "            reduction=self.reduction,\n",
    "            dim=self.dim,\n",
    "        )\n",
    "__all__ = [\"JointLoss\", \"WeightedLoss\"]\n",
    "\n",
    "\n",
    "class WeightedLoss(_Loss):\n",
    "    \"\"\"Wrapper class around loss function that applies weighted with fixed factor.\n",
    "    This class helps to balance multiple losses if they have different scales\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loss, weight=1.0):\n",
    "        super().__init__()\n",
    "        self.loss = loss\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, *input):\n",
    "        return self.loss(*input) * self.weight\n",
    "class JointLoss(_Loss):\n",
    "    \"\"\"\n",
    "    Wrap two loss functions into one. This class computes a weighted sum of two losses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, first: nn.Module, second: nn.Module, first_weight=1.0, second_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.first = WeightedLoss(first, first_weight)\n",
    "        self.second = WeightedLoss(second, second_weight)\n",
    "\n",
    "    def forward(self, *input):\n",
    "        return self.first(*input) + self.second(*input)\n",
    "__all__ = [\"DiceLoss\"]\n",
    "\n",
    "BINARY_MODE = \"binary\"\n",
    "MULTICLASS_MODE = \"multiclass\"\n",
    "MULTILABEL_MODE = \"multilabel\"\n",
    "def soft_dice_score(\n",
    "    output: torch.Tensor, target: torch.Tensor, smooth: float = 0.0, eps: float = 1e-7, dims=None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    :param output:\n",
    "    :param target:\n",
    "    :param smooth:\n",
    "    :param eps:\n",
    "    :return:\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, NC, *)` where :math:`*` means any number\n",
    "            of additional dimensions\n",
    "        - Target: :math:`(N, NC, *)`, same shape as the input\n",
    "        - Output: scalar.\n",
    "\n",
    "    \"\"\"\n",
    "    assert output.size() == target.size()\n",
    "    if dims is not None:\n",
    "        intersection = torch.sum(output * target, dim=dims)\n",
    "        cardinality = torch.sum(output + target, dim=dims)\n",
    "    else:\n",
    "        intersection = torch.sum(output * target)\n",
    "        cardinality = torch.sum(output + target)\n",
    "    dice_score = (2.0 * intersection + smooth) / (cardinality + smooth).clamp_min(eps)\n",
    "    return dice_score\n",
    "class DiceLoss(_Loss):\n",
    "    \"\"\"\n",
    "    Implementation of Dice loss for image segmentation task.\n",
    "    It supports binary, multiclass and multilabel cases\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = 'multiclass',\n",
    "        classes: List[int] = None,\n",
    "        log_loss=False,\n",
    "        from_logits=True,\n",
    "        smooth: float = 0.0,\n",
    "        ignore_index=None,\n",
    "        eps=1e-7,\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        :param mode: Metric mode {'binary', 'multiclass', 'multilabel'}\n",
    "        :param classes: Optional list of classes that contribute in loss computation;\n",
    "        By default, all channels are included.\n",
    "        :param log_loss: If True, loss computed as `-log(jaccard)`; otherwise `1 - jaccard`\n",
    "        :param from_logits: If True assumes input is raw logits\n",
    "        :param smooth:\n",
    "        :param ignore_index: Label that indicates ignored pixels (does not contribute to loss)\n",
    "        :param eps: Small epsilon for numerical stability\n",
    "        \"\"\"\n",
    "        assert mode in {BINARY_MODE, MULTILABEL_MODE, MULTICLASS_MODE}\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.mode = mode\n",
    "        if classes is not None:\n",
    "            assert mode != BINARY_MODE, \"Masking classes is not supported with mode=binary\"\n",
    "            classes = to_tensor(classes, dtype=torch.long)\n",
    "\n",
    "        self.classes = classes\n",
    "        self.from_logits = from_logits\n",
    "        self.smooth = smooth\n",
    "        self.eps = eps\n",
    "        self.ignore_index = ignore_index\n",
    "        self.log_loss = log_loss\n",
    "\n",
    "    def forward(self, y_pred: Tensor, y_true: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        :param y_pred: NxCxHxW\n",
    "        :param y_true: NxHxW\n",
    "        :return: scalar\n",
    "        \"\"\"\n",
    "        assert y_true.size(0) == y_pred.size(0)\n",
    "\n",
    "        if self.from_logits:\n",
    "            # Apply activations to get [0..1] class probabilities\n",
    "            # Using Log-Exp as this gives more numerically stable result and does not cause vanishing gradient on\n",
    "            # extreme values 0 and 1\n",
    "            if self.mode == MULTICLASS_MODE:\n",
    "                y_pred = y_pred.log_softmax(dim=1).exp()\n",
    "            else:\n",
    "                y_pred = F.logsigmoid(y_pred).exp()\n",
    "\n",
    "        bs = y_true.size(0)\n",
    "        num_classes = y_pred.size(1)\n",
    "        dims = (0, 2)\n",
    "\n",
    "        if self.mode == BINARY_MODE:\n",
    "            y_true = y_true.view(bs, 1, -1)\n",
    "            y_pred = y_pred.view(bs, 1, -1)\n",
    "\n",
    "            if self.ignore_index is not None:\n",
    "                mask = y_true != self.ignore_index\n",
    "                y_pred = y_pred * mask\n",
    "                y_true = y_true * mask\n",
    "\n",
    "        if self.mode == MULTICLASS_MODE:\n",
    "            y_true = y_true.view(bs, -1)\n",
    "            y_pred = y_pred.view(bs, num_classes, -1)\n",
    "\n",
    "            if self.ignore_index is not None:\n",
    "                mask = y_true != self.ignore_index\n",
    "                y_pred = y_pred * mask.unsqueeze(1)\n",
    "\n",
    "                y_true = F.one_hot((y_true * mask).to(torch.long), num_classes)  # N,H*W -> N,H*W, C\n",
    "                y_true = y_true.permute(0, 2, 1) * mask.unsqueeze(1)  # H, C, H*W\n",
    "            else:\n",
    "                y_true = F.one_hot(y_true, num_classes)  # N,H*W -> N,H*W, C\n",
    "                y_true = y_true.permute(0, 2, 1)  # H, C, H*W\n",
    "\n",
    "        if self.mode == MULTILABEL_MODE:\n",
    "            y_true = y_true.view(bs, num_classes, -1)\n",
    "            y_pred = y_pred.view(bs, num_classes, -1)\n",
    "\n",
    "            if self.ignore_index is not None:\n",
    "                mask = y_true != self.ignore_index\n",
    "                y_pred = y_pred * mask\n",
    "                y_true = y_true * mask\n",
    "\n",
    "        scores = soft_dice_score(y_pred, y_true.type_as(y_pred), smooth=self.smooth, eps=self.eps, dims=dims)\n",
    "\n",
    "        if self.log_loss:\n",
    "            loss = -torch.log(scores.clamp_min(self.eps))\n",
    "        else:\n",
    "            loss = 1.0 - scores\n",
    "\n",
    "        # Dice loss is undefined for non-empty classes\n",
    "        # So we zero contribution of channel that does not have true pixels\n",
    "        # NOTE: A better workaround would be to use loss term `mean(y_pred)`\n",
    "        # for this case, however it will be a modified jaccard loss\n",
    "\n",
    "        mask = y_true.sum(dims) > 0\n",
    "        loss *= mask.to(loss.dtype)\n",
    "\n",
    "        if self.classes is not None:\n",
    "            loss = loss[self.classes]\n",
    "\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fba7ced9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:06.435491Z",
     "iopub.status.busy": "2023-12-16T11:40:06.434762Z",
     "iopub.status.idle": "2023-12-16T11:40:06.441591Z",
     "shell.execute_reply": "2023-12-16T11:40:06.440750Z"
    },
    "papermill": {
     "duration": 0.022157,
     "end_time": "2023-12-16T11:40:06.443485",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.421328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class UnetLoss(nn.Module):\n",
    "    def __init__(self, ignore_index=255):\n",
    "        super().__init__()\n",
    "        self.main_loss = JointLoss(SoftCrossEntropyLoss(smooth_factor=0.05, ignore_index=ignore_index),\n",
    "                                   DiceLoss(smooth=0.05, ignore_index=ignore_index), 1.0, 1.0)\n",
    "        self.aux_loss = SoftCrossEntropyLoss(smooth_factor=0.05, ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        if self.training and len(logits) == 2:\n",
    "            logit_main, logit_aux = logits\n",
    "            loss = self.main_loss(logit_main, labels) + 0.4 * self.aux_loss(logit_aux, labels)\n",
    "        else:\n",
    "            loss = self.main_loss(logits, labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d509d3b",
   "metadata": {
    "papermill": {
     "duration": 0.012251,
     "end_time": "2023-12-16T11:40:06.468378",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.456127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55becfe3",
   "metadata": {
    "papermill": {
     "duration": 0.012091,
     "end_time": "2023-12-16T11:40:06.492716",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.480625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Initialize weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10af2d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:06.518877Z",
     "iopub.status.busy": "2023-12-16T11:40:06.518535Z",
     "iopub.status.idle": "2023-12-16T11:40:06.523568Z",
     "shell.execute_reply": "2023-12-16T11:40:06.522553Z"
    },
    "papermill": {
     "duration": 0.020615,
     "end_time": "2023-12-16T11:40:06.525557",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.504942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    if isinstance(model, nn.Linear):\n",
    "        # Xavier Distribution\n",
    "        torch.nn.init.xavier_uniform_(model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6383467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:06.552040Z",
     "iopub.status.busy": "2023-12-16T11:40:06.551445Z",
     "iopub.status.idle": "2023-12-16T11:40:06.557268Z",
     "shell.execute_reply": "2023-12-16T11:40:06.556307Z"
    },
    "papermill": {
     "duration": 0.021116,
     "end_time": "2023-12-16T11:40:06.559155",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.538039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, path):\n",
    "    checkpoint = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "def load_model(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0172fd",
   "metadata": {
    "papermill": {
     "duration": 0.012286,
     "end_time": "2023-12-16T11:40:06.583950",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.571664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abca61a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:06.610285Z",
     "iopub.status.busy": "2023-12-16T11:40:06.609944Z",
     "iopub.status.idle": "2023-12-16T11:40:06.627221Z",
     "shell.execute_reply": "2023-12-16T11:40:06.626316Z"
    },
    "papermill": {
     "duration": 0.032923,
     "end_time": "2023-12-16T11:40:06.629300",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.596377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, valid_dataloader, learing_rate_scheduler, epoch, display_step):\n",
    "    print(f\"Start epoch #{epoch+1}, learning rate for this epoch: {learing_rate_scheduler.get_last_lr()}\")\n",
    "    start_time = time.time()\n",
    "    train_loss_epoch = 0\n",
    "    test_loss_epoch = 0\n",
    "    last_loss = 999999999\n",
    "    model.train()\n",
    "    metrics_train = Evaluator(num_class=6)\n",
    "    metrics_val = Evaluator(num_class=6)\n",
    "\n",
    "    for i,input in enumerate(tqdm(train_dataloader)):\n",
    "        # Load data into GPU\n",
    "        data=input['img']\n",
    "        masks_true = input['gt_semantic_seg']\n",
    "        data,mask = data.to(device),masks_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(data)\n",
    "        # Backpropagation, compute gradients\n",
    "        loss = loss_function(prediction, mask.long())\n",
    "        pre_mask = nn.Softmax(dim=1)(prediction)\n",
    "        pre_mask = pre_mask.argmax(dim=1)\n",
    "        for i in range(mask.shape[0]):\n",
    "            metrics_train.add_batch(mask[i].cpu().numpy(), pre_mask[i].cpu().numpy())\n",
    "        loss.backward()\n",
    "\n",
    "        # Apply gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save loss\n",
    "        train_loss_epoch += loss.item()\n",
    "    print(f\"Done epoch #{epoch+1}, time for this epoch: {time.time()-start_time}s\")\n",
    "    train_loss_epoch /= (i + 1)\n",
    "    mIoU = np.nanmean(metrics_train.Intersection_over_Union()[:-1])\n",
    "    F1 = np.nanmean(metrics_train.F1()[:-1])\n",
    "    OA = np.nanmean(metrics_train.OA())\n",
    "    iou_per_class = metrics_train.Intersection_over_Union()\n",
    "    train_eval_value =  (iou_per_class,mIoU,F1,OA)\n",
    "    metrics_train.reset()\n",
    "    # Evaluate the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for k,input in enumerate(tqdm(valid_dataloader)):\n",
    "            data=input['img'].to(device)\n",
    "            mask = input['gt_semantic_seg'].to(device)\n",
    "            prediction = model(data)\n",
    "            test_loss = loss_function(prediction, mask.long())\n",
    "            pre_mask = nn.Softmax(dim=1)(prediction)\n",
    "            pre_mask = pre_mask.argmax(dim=1)\n",
    "            test_loss_epoch += test_loss.item()\n",
    "            if k<=3:\n",
    "            # Convert predictions to 2D array\n",
    "                predictions_2d = pre_mask[0].cpu().numpy()  # Assuming you want the first prediction\n",
    "\n",
    "            # Convert ground truth masks to 2D array\n",
    "                masks_true_2d = mask[0].cpu().numpy()  # Assuming you want the first ground truth mask\n",
    "\n",
    "            # Convert to np.int8 if needed\n",
    "                predictions_2d = predictions_2d.astype(np.int8)\n",
    "                masks_true_2d = masks_true_2d.astype(np.int8)\n",
    "                wandb.log(\n",
    "      {f\"val_image{k}\" : wandb.Image(data[0], masks={\n",
    "        \"predictions\" : {\n",
    "            \"mask_data\" : predictions_2d,\n",
    "            \"class_labels\" : class_label\n",
    "        },\n",
    "        \"ground_truth\" : {\n",
    "            \"mask_data\" : masks_true_2d,\n",
    "            \"class_labels\" : class_label\n",
    "        }\n",
    "    })})\n",
    "            for i in range(mask.shape[0]):\n",
    "                metrics_val.add_batch(mask[i].cpu().numpy(), pre_mask[i].cpu().numpy())\n",
    "    test_loss_epoch /= (i + 1)\n",
    "    mIoU = np.nanmean(metrics_val.Intersection_over_Union()[:-1])\n",
    "    F1 = np.nanmean(metrics_val.F1()[:-1])\n",
    "    OA = np.nanmean(metrics_val.OA())\n",
    "    iou_per_class_val = metrics_val.Intersection_over_Union()\n",
    "    eval_value =  (iou_per_class_val,mIoU,F1,OA)\n",
    "    print(eval_value)\n",
    "    metrics_val.reset()\n",
    "    return train_loss_epoch, train_eval_value, test_loss_epoch, eval_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887d4b1",
   "metadata": {
    "papermill": {
     "duration": 0.012321,
     "end_time": "2023-12-16T11:40:06.654165",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.641844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Test model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41349b4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:06.682083Z",
     "iopub.status.busy": "2023-12-16T11:40:06.681615Z",
     "iopub.status.idle": "2023-12-16T11:40:06.688101Z",
     "shell.execute_reply": "2023-12-16T11:40:06.687204Z"
    },
    "papermill": {
     "duration": 0.022732,
     "end_time": "2023-12-16T11:40:06.690097",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.667365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675e486",
   "metadata": {
    "papermill": {
     "duration": 0.012472,
     "end_time": "2023-12-16T11:40:06.715084",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.702612",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12ad27bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:06.742267Z",
     "iopub.status.busy": "2023-12-16T11:40:06.741434Z",
     "iopub.status.idle": "2023-12-16T11:40:25.171031Z",
     "shell.execute_reply": "2023-12-16T11:40:25.169897Z"
    },
    "papermill": {
     "duration": 18.445716,
     "end_time": "2023-12-16T11:40:25.173453",
     "exception": false,
     "start_time": "2023-12-16T11:40:06.727737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation-models-pytorch\r\n",
      "  Obtaining dependency information for segmentation-models-pytorch from https://files.pythonhosted.org/packages/cb/70/4aac1b240b399b108ce58029ae54bc14497e1bbc275dfab8fd3c84c1e35d/segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata\r\n",
      "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata (30 kB)\r\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\r\n",
      "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\r\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\r\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting timm==0.9.2 (from segmentation-models-pytorch)\r\n",
      "  Obtaining dependency information for timm==0.9.2 from https://files.pythonhosted.org/packages/29/90/94f5deb8d76e24a89813aef95e8809ca8fd7414490428480eda19b133d4a/timm-0.9.2-py3-none-any.whl.metadata\r\n",
      "  Downloading timm-0.9.2-py3-none-any.whl.metadata (68 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\r\n",
      "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\r\n",
      "  Obtaining dependency information for munch from https://files.pythonhosted.org/packages/56/b3/7c69b37f03260a061883bec0e7b05be7117c1b1c85f5212c72c8c2bc3c8c/munch-4.0.0-py2.py3-none-any.whl.metadata\r\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.19.4)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.12.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.11.17)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\r\n",
      "Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-0.9.2-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=04b7b8ef4b41f4d2afcee25cdeab951385d5ab4805898ad14c0cc9ae232c7b55\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=07e968a553bf71c54d414529dbc3011132baa36be48ad5ac3741bf0cd593929d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\r\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\r\n",
      "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 0.9.12\r\n",
      "    Uninstalling timm-0.9.12:\r\n",
      "      Successfully uninstalled timm-0.9.12\r\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7dba5d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:25.206737Z",
     "iopub.status.busy": "2023-12-16T11:40:25.206392Z",
     "iopub.status.idle": "2023-12-16T11:40:31.076009Z",
     "shell.execute_reply": "2023-12-16T11:40:31.074474Z"
    },
    "papermill": {
     "duration": 5.889298,
     "end_time": "2023-12-16T11:40:31.078732",
     "exception": false,
     "start_time": "2023-12-16T11:40:25.189434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 219MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UnetPlusPlus(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetPlusPlusDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleDict(\n",
       "      (x_0_0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_3_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=6     \n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d75959a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:31.113467Z",
     "iopub.status.busy": "2023-12-16T11:40:31.112965Z",
     "iopub.status.idle": "2023-12-16T11:40:31.118291Z",
     "shell.execute_reply": "2023-12-16T11:40:31.117434Z"
    },
    "papermill": {
     "duration": 0.024612,
     "end_time": "2023-12-16T11:40:31.120097",
     "exception": false,
     "start_time": "2023-12-16T11:40:31.095485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Use GPU-accelerated PyTorch functions here\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83c3915c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:31.155016Z",
     "iopub.status.busy": "2023-12-16T11:40:31.154678Z",
     "iopub.status.idle": "2023-12-16T11:40:31.161741Z",
     "shell.execute_reply": "2023-12-16T11:40:31.160844Z"
    },
    "papermill": {
     "duration": 0.026641,
     "end_time": "2023-12-16T11:40:31.163598",
     "exception": false,
     "start_time": "2023-12-16T11:40:31.136957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_function = UnetLoss(ignore_index=6)\n",
    "# Define the optimizer (Adam optimizer)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "learing_rate_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f67bc8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:31.197727Z",
     "iopub.status.busy": "2023-12-16T11:40:31.197418Z",
     "iopub.status.idle": "2023-12-16T11:40:31.367171Z",
     "shell.execute_reply": "2023-12-16T11:40:31.366301Z"
    },
    "papermill": {
     "duration": 0.189218,
     "end_time": "2023-12-16T11:40:31.369532",
     "exception": false,
     "start_time": "2023-12-16T11:40:31.180314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model(model, optimizer, checkpoint_path)\n",
    "load_checkpoint_flag=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8414275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:31.405185Z",
     "iopub.status.busy": "2023-12-16T11:40:31.404824Z",
     "iopub.status.idle": "2023-12-16T11:40:31.408801Z",
     "shell.execute_reply": "2023-12-16T11:40:31.407953Z"
    },
    "papermill": {
     "duration": 0.024049,
     "end_time": "2023-12-16T11:40:31.410652",
     "exception": false,
     "start_time": "2023-12-16T11:40:31.386603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Model keys:\")\n",
    "# print(model.state_dict().keys())\n",
    "\n",
    "# print(\"\\nCheckpoint keys:\")\n",
    "# print(checkpoint['model'].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e4c5e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:31.445025Z",
     "iopub.status.busy": "2023-12-16T11:40:31.444351Z",
     "iopub.status.idle": "2023-12-16T11:40:31.448806Z",
     "shell.execute_reply": "2023-12-16T11:40:31.447935Z"
    },
    "papermill": {
     "duration": 0.023562,
     "end_time": "2023-12-16T11:40:31.450732",
     "exception": false,
     "start_time": "2023-12-16T11:40:31.427170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the model checkpoint if needed\n",
    "# Load the model checkpoint if needed\n",
    "if load_checkpoint_flag:\n",
    "    model, optimize= load_model(model, optimizer, pretrained_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49795f03",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:31.484580Z",
     "iopub.status.busy": "2023-12-16T11:40:31.484200Z",
     "iopub.status.idle": "2023-12-16T11:40:31.488598Z",
     "shell.execute_reply": "2023-12-16T11:40:31.487859Z"
    },
    "papermill": {
     "duration": 0.023546,
     "end_time": "2023-12-16T11:40:31.490504",
     "exception": false,
     "start_time": "2023-12-16T11:40:31.466958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "655441d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:40:31.524887Z",
     "iopub.status.busy": "2023-12-16T11:40:31.524536Z",
     "iopub.status.idle": "2023-12-16T11:41:03.448987Z",
     "shell.execute_reply": "2023-12-16T11:41:03.447898Z"
    },
    "papermill": {
     "duration": 31.952428,
     "end_time": "2023-12-16T11:41:03.459484",
     "exception": false,
     "start_time": "2023-12-16T11:40:31.507056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrithuy2003\u001b[0m (\u001b[33mdeepbk\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231216_114033-ubeetgwe\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhelpful-eon-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/deepbk/unetplusplus_tuning\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/deepbk/unetplusplus_tuning/runs/ubeetgwe\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/deepbk/unetplusplus_tuning/runs/ubeetgwe?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7995a9bca5f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wandb.login(\n",
    "    # set the wandb project where this run will be logged\n",
    "#     project= \"PolypSegment\", \n",
    "    key = \"b98d2b806f364f5af900550ec98e26e2f418e8a7\",\n",
    ")\n",
    "wandb.init(\n",
    "    project = \"unetplusplus_tuning\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57a577a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T11:41:03.497858Z",
     "iopub.status.busy": "2023-12-16T11:41:03.497121Z",
     "iopub.status.idle": "2023-12-16T13:27:45.437295Z",
     "shell.execute_reply": "2023-12-16T13:27:45.436379Z"
    },
    "papermill": {
     "duration": 6401.961896,
     "end_time": "2023-12-16T13:27:45.439562",
     "exception": false,
     "start_time": "2023-12-16T11:41:03.477666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch #1, learning rate for this epoch: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [04:05<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #1, time for this epoch: 245.98548126220703s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:20<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.49148501, 0.39317315, 0.22669158, 0.29615695, 0.5553317 ,\n",
      "       0.04467074]), 0.39256767777341944, 0.5528317637345344, 0.5238985169815314)\n",
      "train: {'mIoU': 0.4532835015379728, 'F1': 0.6207107097769999, 'OA': 0.6372596331131763}\n",
      "{'ImSurf': 0.4925088031720075, 'Building': 0.5095192321219401, 'LowVeg': 0.47614477805557953, 'Tree': 0.4649576011363042, 'Car': 0.32328709320403265, 'Clutter': 0.03316370096161863}\n",
      "val: {'mIoU': 0.39256767777341944, 'F1': 0.5528317637345344, 'OA': 0.5238985169815314}\n",
      "{'ImSurf': 0.49148501014474455, 'Building': 0.3931731522834272, 'LowVeg': 0.22669157805251644, 'Tree': 0.2961569473463578, 'Car': 0.555331701040051, 'Clutter': 0.044670744935739894}\n",
      "Epoch 1: loss: 32.4185, train accuracy: 0.6373, valid accuracy:0.5239\n",
      "Start epoch #2, learning rate for this epoch: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:37<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #2, time for this epoch: 157.2873854637146s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:13<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.5697355 , 0.58815152, 0.51622865, 0.41012205, 0.62291768,\n",
      "       0.1830455 ]), 0.5414310781994266, 0.6993693398262716, 0.684102186434404)\n",
      "train: {'mIoU': 0.5695009705619323, 'F1': 0.725314232111532, 'OA': 0.7053619928849049}\n",
      "{'ImSurf': 0.5635724470399377, 'Building': 0.6138469146508824, 'LowVeg': 0.5439079319713466, 'Tree': 0.5395162608526268, 'Car': 0.5866612982948679, 'Clutter': 0.12268184763547786}\n",
      "val: {'mIoU': 0.5414310781994266, 'F1': 0.6993693398262716, 'OA': 0.684102186434404}\n",
      "{'ImSurf': 0.5697354982418809, 'Building': 0.5881515168796646, 'LowVeg': 0.516228651617797, 'Tree': 0.410122047626136, 'Car': 0.6229176766316545, 'Clutter': 0.18304549797101616}\n",
      "Epoch 2: loss: 27.6150, train accuracy: 0.7054, valid accuracy:0.6841\n",
      "Start epoch #3, learning rate for this epoch: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:34<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #3, time for this epoch: 154.9977161884308s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:13<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.62878611, 0.70707525, 0.59355653, 0.56433463, 0.59790254,\n",
      "       0.19023967]), 0.6183310111323804, 0.7630606461265137, 0.7530926158765365)\n",
      "train: {'mIoU': 0.5998024806672072, 'F1': 0.7492386335206922, 'OA': 0.7283915495261167}\n",
      "{'ImSurf': 0.5900846656684505, 'Building': 0.6513248792340494, 'LowVeg': 0.5599041580776185, 'Tree': 0.5679587758886191, 'Car': 0.6297399244672983, 'Clutter': 0.18147540819507002}\n",
      "val: {'mIoU': 0.6183310111323804, 'F1': 0.7630606461265137, 'OA': 0.7530926158765365}\n",
      "{'ImSurf': 0.6287861052366549, 'Building': 0.7070752503388352, 'LowVeg': 0.5935565284588722, 'Tree': 0.564334634728173, 'Car': 0.5979025368993667, 'Clutter': 0.19023966816507304}\n",
      "Epoch 3: loss: 26.0036, train accuracy: 0.7284, valid accuracy:0.7531\n",
      "Start epoch #4, learning rate for this epoch: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:31<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #4, time for this epoch: 151.93644738197327s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:13<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.63982642, 0.69662509, 0.54565317, 0.56939215, 0.61949151,\n",
      "       0.22955851]), 0.6141976683526021, 0.7596524562753995, 0.7452782865744738)\n",
      "train: {'mIoU': 0.6252773554060941, 'F1': 0.7686255699543448, 'OA': 0.748531848956377}\n",
      "{'ImSurf': 0.6211583329922186, 'Building': 0.6888596599177002, 'LowVeg': 0.5742252129894326, 'Tree': 0.588676919737401, 'Car': 0.6534666513937182, 'Clutter': 0.20859103807347282}\n",
      "val: {'mIoU': 0.6141976683526021, 'F1': 0.7596524562753995, 'OA': 0.7452782865744738}\n",
      "{'ImSurf': 0.6398264182737963, 'Building': 0.696625087894814, 'LowVeg': 0.5456531721916023, 'Tree': 0.5693921489739654, 'Car': 0.6194915144288324, 'Clutter': 0.22955850830320784}\n",
      "Epoch 4: loss: 24.6364, train accuracy: 0.7485, valid accuracy:0.7453\n",
      "Start epoch #5, learning rate for this epoch: [0.0006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:30<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #5, time for this epoch: 150.35812330245972s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.66163007, 0.75982304, 0.63100817, 0.62871867, 0.7131503 ,\n",
      "       0.28682561]), 0.6788660482538493, 0.8076500552541077, 0.7856555508779948)\n",
      "train: {'mIoU': 0.6491442150171594, 'F1': 0.7862815204826796, 'OA': 0.7678029170403113}\n",
      "{'ImSurf': 0.6400406785633075, 'Building': 0.7257112298997074, 'LowVeg': 0.5969122645211444, 'Tree': 0.608320205972186, 'Car': 0.6747366961294513, 'Clutter': 0.24681267269210105}\n",
      "val: {'mIoU': 0.6788660482538493, 'F1': 0.8076500552541077, 'OA': 0.7856555508779948}\n",
      "{'ImSurf': 0.6616300673974217, 'Building': 0.7598230353235026, 'LowVeg': 0.6310081678960419, 'Tree': 0.6287186729351133, 'Car': 0.7131502977171672, 'Clutter': 0.2868256115457465}\n",
      "Epoch 5: loss: 23.2898, train accuracy: 0.7678, valid accuracy:0.7857\n",
      "Start epoch #6, learning rate for this epoch: [0.0006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:27<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #6, time for this epoch: 147.56595730781555s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.66104669, 0.76141717, 0.65210152, 0.64754595, 0.6549637 ,\n",
      "       0.27948944]), 0.675415006551952, 0.8054997595449741, 0.7946489475137966)\n",
      "train: {'mIoU': 0.6709861141895115, 'F1': 0.8018858383999492, 'OA': 0.7842365442178189}\n",
      "{'ImSurf': 0.6589070470009943, 'Building': 0.7597685992089239, 'LowVeg': 0.6096560934560723, 'Tree': 0.6279841892986925, 'Car': 0.6986146419828739, 'Clutter': 0.2688760467197292}\n",
      "val: {'mIoU': 0.675415006551952, 'F1': 0.8054997595449741, 'OA': 0.7946489475137966}\n",
      "{'ImSurf': 0.6610466864131641, 'Building': 0.7614171733534367, 'LowVeg': 0.6521015237006849, 'Tree': 0.6475459483316293, 'Car': 0.6549637009608449, 'Clutter': 0.27948943991996256}\n",
      "Epoch 6: loss: 22.2682, train accuracy: 0.7842, valid accuracy:0.7946\n",
      "Start epoch #7, learning rate for this epoch: [0.0006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #7, time for this epoch: 146.22972059249878s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.66410118, 0.77405513, 0.61840101, 0.55324045, 0.68440387,\n",
      "       0.30040872]), 0.6588403275470279, 0.7920014641111587, 0.7797805665639861)\n",
      "train: {'mIoU': 0.6776258566737998, 'F1': 0.8064968000614765, 'OA': 0.7904229072424082}\n",
      "{'ImSurf': 0.6691015980515178, 'Building': 0.7763421905522322, 'LowVeg': 0.6117344910626809, 'Tree': 0.6362116878709003, 'Car': 0.694739315831668, 'Clutter': 0.2797059141308714}\n",
      "val: {'mIoU': 0.6588403275470279, 'F1': 0.7920014641111587, 'OA': 0.7797805665639861}\n",
      "{'ImSurf': 0.6641011799273487, 'Building': 0.7740551289241119, 'LowVeg': 0.6184010132979293, 'Tree': 0.553240447680913, 'Car': 0.6844038679048363, 'Clutter': 0.3004087183570836}\n",
      "Epoch 7: loss: 21.7863, train accuracy: 0.7904, valid accuracy:0.7798\n",
      "Start epoch #8, learning rate for this epoch: [0.0006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:27<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #8, time for this epoch: 147.09640336036682s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.67894271, 0.78648003, 0.65435335, 0.64218089, 0.68992647,\n",
      "       0.30037939]), 0.6903766890597518, 0.8157893084753752, 0.8036734861002837)\n",
      "train: {'mIoU': 0.687990856685629, 'F1': 0.8139664906348101, 'OA': 0.799206480001792}\n",
      "{'ImSurf': 0.6804282151132726, 'Building': 0.7854894068232656, 'LowVeg': 0.6301589020674784, 'Tree': 0.6466505563133417, 'Car': 0.6972272031107869, 'Clutter': 0.289278730095502}\n",
      "val: {'mIoU': 0.6903766890597518, 'F1': 0.8157893084753752, 'OA': 0.8036734861002837}\n",
      "{'ImSurf': 0.6789427072359699, 'Building': 0.7864800310277957, 'LowVeg': 0.6543533469323096, 'Tree': 0.6421808862317612, 'Car': 0.6899264738709223, 'Clutter': 0.30037939496426896}\n",
      "Epoch 8: loss: 21.2492, train accuracy: 0.7992, valid accuracy:0.8037\n",
      "Start epoch #9, learning rate for this epoch: [0.00035999999999999997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:29<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #9, time for this epoch: 149.25019001960754s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.69196384, 0.78557859, 0.65704864, 0.64321065, 0.70681367,\n",
      "       0.3411858 ]), 0.6969230769380429, 0.8203975748985926, 0.8070837542553727)\n",
      "train: {'mIoU': 0.6998909123401265, 'F1': 0.8221989299241848, 'OA': 0.8093099685815665}\n",
      "{'ImSurf': 0.6922735327349597, 'Building': 0.8040873907579437, 'LowVeg': 0.6428088430524221, 'Tree': 0.6585882372280983, 'Car': 0.701696557927208, 'Clutter': 0.3191106762668621}\n",
      "val: {'mIoU': 0.6969230769380429, 'F1': 0.8203975748985926, 'OA': 0.8070837542553727}\n",
      "{'ImSurf': 0.6919638355884884, 'Building': 0.7855785888617752, 'LowVeg': 0.6570486401874206, 'Tree': 0.64321064688112, 'Car': 0.7068136731714103, 'Clutter': 0.3411858027989064}\n",
      "Epoch 9: loss: 20.5142, train accuracy: 0.8093, valid accuracy:0.8071\n",
      "Start epoch #10, learning rate for this epoch: [0.00035999999999999997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #10, time for this epoch: 145.51325583457947s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.69570107, 0.78972706, 0.66275656, 0.64821025, 0.72731671,\n",
      "       0.36350424]), 0.704742327806695, 0.8257866836277625, 0.8110590467158615)\n",
      "train: {'mIoU': 0.71019762363591, 'F1': 0.829404350905633, 'OA': 0.8172219838851538}\n",
      "{'ImSurf': 0.6975754892338748, 'Building': 0.8103380956972431, 'LowVeg': 0.6546741412003106, 'Tree': 0.6730469219466413, 'Car': 0.71535347010148, 'Clutter': 0.34729347563488566}\n",
      "val: {'mIoU': 0.704742327806695, 'F1': 0.8257866836277625, 'OA': 0.8110590467158615}\n",
      "{'ImSurf': 0.6957010666519877, 'Building': 0.7897270614898142, 'LowVeg': 0.6627565581387772, 'Tree': 0.648210246700011, 'Car': 0.7273167060528851, 'Clutter': 0.3635042419259991}\n",
      "Epoch 10: loss: 19.9222, train accuracy: 0.8172, valid accuracy:0.8111\n",
      "Start epoch #11, learning rate for this epoch: [0.00035999999999999997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:22<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #11, time for this epoch: 142.95338439941406s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.72188572, 0.81805266, 0.67688501, 0.67486097, 0.7130102 ,\n",
      "       0.37335065]), 0.7209389114308824, 0.8368105238399849, 0.8255070825317995)\n",
      "train: {'mIoU': 0.7227507668279171, 'F1': 0.8379828147824646, 'OA': 0.8249520980394803}\n",
      "{'ImSurf': 0.7153145078207781, 'Building': 0.8200059107094332, 'LowVeg': 0.6682120829885568, 'Tree': 0.6816459892374868, 'Car': 0.7285753433833303, 'Clutter': 0.35025727626642444}\n",
      "val: {'mIoU': 0.7209389114308824, 'F1': 0.8368105238399849, 'OA': 0.8255070825317995}\n",
      "{'ImSurf': 0.7218857182936756, 'Building': 0.8180526573239801, 'LowVeg': 0.6768850091560205, 'Tree': 0.6748609749469752, 'Car': 0.7130101974337607, 'Clutter': 0.373350653141356}\n",
      "Epoch 11: loss: 19.4415, train accuracy: 0.8250, valid accuracy:0.8255\n",
      "Start epoch #12, learning rate for this epoch: [0.00035999999999999997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #12, time for this epoch: 144.60337114334106s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.70777492, 0.80619306, 0.67687987, 0.68099915, 0.71275033,\n",
      "       0.30540646]), 0.716919465402427, 0.834282348706877, 0.821908122416631)\n",
      "train: {'mIoU': 0.7275778886127211, 'F1': 0.8410699529562942, 'OA': 0.8287545962211413}\n",
      "{'ImSurf': 0.7230385104350758, 'Building': 0.8308243584673014, 'LowVeg': 0.6644816953779402, 'Tree': 0.686376609789768, 'Car': 0.7331682689935195, 'Clutter': 0.3579062060408415}\n",
      "val: {'mIoU': 0.716919465402427, 'F1': 0.834282348706877, 'OA': 0.821908122416631}\n",
      "{'ImSurf': 0.7077749157038408, 'Building': 0.8061930606419514, 'LowVeg': 0.6768798718796861, 'Tree': 0.6809991516168322, 'Car': 0.7127503271698241, 'Clutter': 0.30540645904778635}\n",
      "Epoch 12: loss: 19.1238, train accuracy: 0.8288, valid accuracy:0.8219\n",
      "Start epoch #13, learning rate for this epoch: [0.00021599999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #13, time for this epoch: 145.34250235557556s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.70867138, 0.81488035, 0.67536875, 0.67981687, 0.72385758,\n",
      "       0.36876097]), 0.7205189852926389, 0.8365874439323541, 0.8251586278736034)\n",
      "train: {'mIoU': 0.7320731077418701, 'F1': 0.8440522240535403, 'OA': 0.8334869421445407}\n",
      "{'ImSurf': 0.7279420904457599, 'Building': 0.8386477993834766, 'LowVeg': 0.6719943690079871, 'Tree': 0.688600094633415, 'Car': 0.7331811852387119, 'Clutter': 0.38719201749550214}\n",
      "val: {'mIoU': 0.7205189852926389, 'F1': 0.8365874439323541, 'OA': 0.8251586278736034}\n",
      "{'ImSurf': 0.7086713774515738, 'Building': 0.8148803529234678, 'LowVeg': 0.6753687493474795, 'Tree': 0.6798168676774755, 'Car': 0.7238575790631981, 'Clutter': 0.36876097282612447}\n",
      "Epoch 13: loss: 18.7568, train accuracy: 0.8335, valid accuracy:0.8252\n",
      "Start epoch #14, learning rate for this epoch: [0.00021599999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:23<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #14, time for this epoch: 143.74289083480835s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.72357888, 0.83942986, 0.68646636, 0.67293894, 0.74247783,\n",
      "       0.39001377]), 0.732978374216038, 0.8446254098663376, 0.832339284750342)\n",
      "train: {'mIoU': 0.743607651130753, 'F1': 0.8517825989701304, 'OA': 0.8402083042340401}\n",
      "{'ImSurf': 0.7383851735695764, 'Building': 0.8449944686449643, 'LowVeg': 0.6841590697400299, 'Tree': 0.6989537628611738, 'Car': 0.7515457808380199, 'Clutter': 0.3965619696623727}\n",
      "val: {'mIoU': 0.732978374216038, 'F1': 0.8446254098663376, 'OA': 0.832339284750342}\n",
      "{'ImSurf': 0.7235788828612871, 'Building': 0.8394298609117367, 'LowVeg': 0.6864663621659254, 'Tree': 0.672938935491571, 'Car': 0.7424778296496694, 'Clutter': 0.3900137688162062}\n",
      "Epoch 14: loss: 18.2564, train accuracy: 0.8402, valid accuracy:0.8323\n",
      "Start epoch #15, learning rate for this epoch: [0.00021599999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:23<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #15, time for this epoch: 143.4240550994873s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.71965225, 0.82144944, 0.68588521, 0.69190948, 0.74139342,\n",
      "       0.39378495]), 0.732057958745856, 0.8444050497035794, 0.8316958195343345)\n",
      "train: {'mIoU': 0.7458697723777983, 'F1': 0.8529911435293798, 'OA': 0.8427750636369754}\n",
      "{'ImSurf': 0.7442591838084346, 'Building': 0.860314045752262, 'LowVeg': 0.6782011375876793, 'Tree': 0.6995390016309331, 'Car': 0.7470354931096828, 'Clutter': 0.41346342657064017}\n",
      "val: {'mIoU': 0.732057958745856, 'F1': 0.8444050497035794, 'OA': 0.8316958195343345}\n",
      "{'ImSurf': 0.7196522470780271, 'Building': 0.8214494373583028, 'LowVeg': 0.6858852050038642, 'Tree': 0.6919094805135058, 'Car': 0.7413934237755806, 'Clutter': 0.3937849531420684}\n",
      "Epoch 15: loss: 18.1001, train accuracy: 0.8428, valid accuracy:0.8317\n",
      "Start epoch #16, learning rate for this epoch: [0.00021599999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:23<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #16, time for this epoch: 143.88951539993286s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/88 [00:00<?, ?it/s]Exception in thread Thread-24 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 51, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 307, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/resource_sharer.py\", line 58, in detach\n",
      "    return reduction.recv_handle(conn)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 189, in recv_handle\n",
      "    return recvfds(s, 1)[0]\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 159, in recvfds\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  0%|          | 0/88 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch #17, learning rate for this epoch: [0.00021599999999999996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:22<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #17, time for this epoch: 142.66866254806519s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.73196445, 0.84086652, 0.69701635, 0.69910686, 0.74280713,\n",
      "       0.39924847]), 0.742352261910202, 0.8511190128297231, 0.8407025142102812)\n",
      "train: {'mIoU': 0.7488389525700956, 'F1': 0.8551550083360075, 'OA': 0.8444191156289517}\n",
      "{'ImSurf': 0.7422616440898954, 'Building': 0.8551450207584296, 'LowVeg': 0.6887453867710601, 'Tree': 0.7049002429344426, 'Car': 0.7531424682966503, 'Clutter': 0.4196658765763408}\n",
      "val: {'mIoU': 0.742352261910202, 'F1': 0.8511190128297231, 'OA': 0.8407025142102812}\n",
      "{'ImSurf': 0.7319644497881747, 'Building': 0.8408665200679519, 'LowVeg': 0.6970163543381792, 'Tree': 0.6991068573348189, 'Car': 0.7428071280218844, 'Clutter': 0.3992484706124536}\n",
      "Epoch 17: loss: 17.9054, train accuracy: 0.8444, valid accuracy:0.8407\n",
      "Start epoch #18, learning rate for this epoch: [0.00012959999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #18, time for this epoch: 145.7529718875885s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.73543226, 0.83755143, 0.68714832, 0.68577281, 0.7354291 ,\n",
      "       0.41263367]), 0.7362667833816513, 0.8469720017694963, 0.8363998314500795)\n",
      "train: {'mIoU': 0.756467627260798, 'F1': 0.8600651775442725, 'OA': 0.8526855554336157}\n",
      "{'ImSurf': 0.7586951790454848, 'Building': 0.8679433678393441, 'LowVeg': 0.6965622397892048, 'Tree': 0.7134337416118659, 'Car': 0.7457036080180908, 'Clutter': 0.4407102656557636}\n",
      "val: {'mIoU': 0.7362667833816513, 'F1': 0.8469720017694963, 'OA': 0.8363998314500795}\n",
      "{'ImSurf': 0.7354322551563184, 'Building': 0.8375514311505661, 'LowVeg': 0.6871483242280177, 'Tree': 0.6857728086425883, 'Car': 0.7354290977307657, 'Clutter': 0.41263367403603496}\n",
      "Epoch 18: loss: 17.4237, train accuracy: 0.8527, valid accuracy:0.8364\n",
      "Start epoch #19, learning rate for this epoch: [0.00012959999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #19, time for this epoch: 145.88532638549805s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.73851255, 0.8527195 , 0.69872678, 0.70263253, 0.7359299 ,\n",
      "       0.44572488]), 0.7457042513294695, 0.8531945683413655, 0.8440433784260307)\n",
      "train: {'mIoU': 0.7610688677693443, 'F1': 0.8630828318701017, 'OA': 0.8549642990796994}\n",
      "{'ImSurf': 0.7593042067681237, 'Building': 0.869238032078634, 'LowVeg': 0.7031002972958962, 'Tree': 0.7120284394361825, 'Car': 0.7616733632678848, 'Clutter': 0.4508805111872041}\n",
      "val: {'mIoU': 0.7457042513294695, 'F1': 0.8531945683413655, 'OA': 0.8440433784260307}\n",
      "{'ImSurf': 0.7385125489995618, 'Building': 0.852719496703637, 'LowVeg': 0.6987267786948296, 'Tree': 0.7026325329616188, 'Car': 0.7359298992877001, 'Clutter': 0.4457248783394439}\n",
      "Epoch 19: loss: 17.1715, train accuracy: 0.8550, valid accuracy:0.8440\n",
      "Start epoch #20, learning rate for this epoch: [0.00012959999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:24<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #20, time for this epoch: 144.8816409111023s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.71187126, 0.81636755, 0.6694267 , 0.69404847, 0.74233905,\n",
      "       0.41739907]), 0.7268106056995369, 0.8408174159940242, 0.8265757345074983)\n",
      "train: {'mIoU': 0.7649928993928112, 'F1': 0.8655768760381779, 'OA': 0.8579800373468643}\n",
      "{'ImSurf': 0.7674072442808364, 'Building': 0.8738813434030677, 'LowVeg': 0.7032423449155022, 'Tree': 0.7168121164543567, 'Car': 0.7636214479102927, 'Clutter': 0.47522686935303193}\n",
      "val: {'mIoU': 0.7268106056995369, 'F1': 0.8408174159940242, 'OA': 0.8265757345074983}\n",
      "{'ImSurf': 0.7118712590248204, 'Building': 0.8163675505740842, 'LowVeg': 0.6694267018352933, 'Tree': 0.6940484654385962, 'Car': 0.7423390516248907, 'Clutter': 0.41739906527225057}\n",
      "Epoch 20: loss: 16.9344, train accuracy: 0.8580, valid accuracy:0.8266\n",
      "Start epoch #21, learning rate for this epoch: [0.00012959999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:25<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #21, time for this epoch: 145.05205488204956s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74146687, 0.85045579, 0.70783082, 0.68624603, 0.73031168,\n",
      "       0.40360463]), 0.7432622371824522, 0.8515448490710817, 0.843232285608427)\n",
      "train: {'mIoU': 0.7640861973343294, 'F1': 0.8650520254025528, 'OA': 0.8578353478358343}\n",
      "{'ImSurf': 0.7683241711708583, 'Building': 0.8710682245256253, 'LowVeg': 0.7057870484031693, 'Tree': 0.7163094566059249, 'Car': 0.758942085966069, 'Clutter': 0.4625339290273055}\n",
      "val: {'mIoU': 0.7432622371824522, 'F1': 0.8515448490710817, 'OA': 0.843232285608427}\n",
      "{'ImSurf': 0.7414668689742955, 'Building': 0.8504557859252478, 'LowVeg': 0.7078308214814567, 'Tree': 0.6862460269826816, 'Car': 0.7303116825485799, 'Clutter': 0.40360463109809847}\n",
      "Epoch 21: loss: 17.0140, train accuracy: 0.8578, valid accuracy:0.8432\n",
      "Start epoch #22, learning rate for this epoch: [7.775999999999999e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:22<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #22, time for this epoch: 142.32923436164856s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:13<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74002451, 0.84453196, 0.69750021, 0.70189195, 0.74584073,\n",
      "       0.42943987]), 0.7459578684906509, 0.8534718575982229, 0.8436430022601847)\n",
      "train: {'mIoU': 0.7738578855551167, 'F1': 0.8713010721012043, 'OA': 0.8648877357825254}\n",
      "{'ImSurf': 0.7785814861670434, 'Building': 0.8833215069205594, 'LowVeg': 0.7188290106337667, 'Tree': 0.7258840123009648, 'Car': 0.7626734117532491, 'Clutter': 0.48153539601644246}\n",
      "val: {'mIoU': 0.7459578684906509, 'F1': 0.8534718575982229, 'OA': 0.8436430022601847}\n",
      "{'ImSurf': 0.7400245070282402, 'Building': 0.8445319550667008, 'LowVeg': 0.6975002067433814, 'Tree': 0.7018919481648441, 'Car': 0.7458407254500884, 'Clutter': 0.42943986810751117}\n",
      "Epoch 22: loss: 16.5226, train accuracy: 0.8649, valid accuracy:0.8436\n",
      "Start epoch #23, learning rate for this epoch: [7.775999999999999e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:23<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #23, time for this epoch: 143.47148275375366s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74500483, 0.84005155, 0.7014557 , 0.69641948, 0.74495167,\n",
      "       0.44006706]), 0.7455766475244159, 0.8532728041186791, 0.8439818722518843)\n",
      "train: {'mIoU': 0.7733774029402392, 'F1': 0.8710178791416057, 'OA': 0.8636940381465814}\n",
      "{'ImSurf': 0.7724433751803105, 'Building': 0.8816785331750066, 'LowVeg': 0.7163224941213576, 'Tree': 0.7274851886502351, 'Car': 0.7689574235742858, 'Clutter': 0.4760155512592716}\n",
      "val: {'mIoU': 0.7455766475244159, 'F1': 0.8532728041186791, 'OA': 0.8439818722518843}\n",
      "{'ImSurf': 0.7450048307613945, 'Building': 0.8400515535218354, 'LowVeg': 0.7014557010688004, 'Tree': 0.6964194846173983, 'Car': 0.7449516676526504, 'Clutter': 0.44006705564861587}\n",
      "Epoch 23: loss: 16.5893, train accuracy: 0.8637, valid accuracy:0.8440\n",
      "Start epoch #24, learning rate for this epoch: [7.775999999999999e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:21<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #24, time for this epoch: 141.6481077671051s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74002931, 0.84983844, 0.70456727, 0.69528592, 0.75005874,\n",
      "       0.41782648]), 0.7479559384444522, 0.8547078966904931, 0.8452793841557115)\n",
      "train: {'mIoU': 0.7712420741386954, 'F1': 0.8696316771449878, 'OA': 0.864136992356716}\n",
      "{'ImSurf': 0.7733142360024289, 'Building': 0.8817475108408194, 'LowVeg': 0.7150994198565541, 'Tree': 0.7270221685505155, 'Car': 0.7590270354431587, 'Clutter': 0.5010682188584197}\n",
      "val: {'mIoU': 0.7479559384444522, 'F1': 0.8547078966904931, 'OA': 0.8452793841557115}\n",
      "{'ImSurf': 0.7400293134626446, 'Building': 0.8498384420612468, 'LowVeg': 0.7045672734172239, 'Tree': 0.6952859224736434, 'Car': 0.750058740807502, 'Clutter': 0.41782647956482516}\n",
      "Epoch 24: loss: 16.5111, train accuracy: 0.8641, valid accuracy:0.8453\n",
      "Start epoch #25, learning rate for this epoch: [7.775999999999999e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:21<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #25, time for this epoch: 141.19016814231873s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74216572, 0.83667352, 0.70132196, 0.70810697, 0.72969376,\n",
      "       0.40279458]), 0.743592387620453, 0.8520722171434203, 0.8439323825110484)\n",
      "train: {'mIoU': 0.775144102912354, 'F1': 0.8722046451077634, 'OA': 0.8658422231674194}\n",
      "{'ImSurf': 0.7808384874204043, 'Building': 0.8809680303292053, 'LowVeg': 0.7209319660085485, 'Tree': 0.7318776255828019, 'Car': 0.7611044052208101, 'Clutter': 0.4767230915921516}\n",
      "val: {'mIoU': 0.743592387620453, 'F1': 0.8520722171434203, 'OA': 0.8439323825110484}\n",
      "{'ImSurf': 0.7421657199621318, 'Building': 0.8366735224068892, 'LowVeg': 0.7013219642260584, 'Tree': 0.7081069682198883, 'Car': 0.7296937632872977, 'Clutter': 0.40279458318988315}\n",
      "Epoch 25: loss: 16.3996, train accuracy: 0.8658, valid accuracy:0.8439\n",
      "Start epoch #26, learning rate for this epoch: [4.665599999999999e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:22<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #26, time for this epoch: 142.71455574035645s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.72338394, 0.83212975, 0.69512177, 0.69552487, 0.73483032,\n",
      "       0.40262851]), 0.7361981298767196, 0.8471168542140921, 0.8365866283846688)\n",
      "train: {'mIoU': 0.7765393699991205, 'F1': 0.8729638521721726, 'OA': 0.8683661130758432}\n",
      "{'ImSurf': 0.783183619674281, 'Building': 0.8883671849206968, 'LowVeg': 0.7184732045612607, 'Tree': 0.7325867090012279, 'Car': 0.7600861318381361, 'Clutter': 0.5083147961244512}\n",
      "val: {'mIoU': 0.7361981298767196, 'F1': 0.8471168542140921, 'OA': 0.8365866283846688}\n",
      "{'ImSurf': 0.7233839403821006, 'Building': 0.8321297497321292, 'LowVeg': 0.6951217732874744, 'Tree': 0.6955248688211673, 'Car': 0.7348303171607269, 'Clutter': 0.4026285142929279}\n",
      "Epoch 26: loss: 16.2443, train accuracy: 0.8684, valid accuracy:0.8366\n",
      "Start epoch #27, learning rate for this epoch: [4.665599999999999e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:22<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #27, time for this epoch: 142.58886456489563s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74925665, 0.85235983, 0.71878348, 0.70779009, 0.75054548,\n",
      "       0.43990166]), 0.7557471023617236, 0.8599469048731313, 0.8514627756528175)\n",
      "train: {'mIoU': 0.779067651215287, 'F1': 0.8746526031245025, 'OA': 0.869708348543216}\n",
      "{'ImSurf': 0.7869745170394059, 'Building': 0.8857575260467193, 'LowVeg': 0.7259732583010589, 'Tree': 0.7295618935598076, 'Car': 0.7670710611294429, 'Clutter': 0.5162990138367415}\n",
      "val: {'mIoU': 0.7557471023617236, 'F1': 0.8599469048731313, 'OA': 0.8514627756528175}\n",
      "{'ImSurf': 0.749256648336691, 'Building': 0.8523598265085983, 'LowVeg': 0.7187834750850834, 'Tree': 0.7077900864361631, 'Car': 0.750545475442082, 'Clutter': 0.4399016632583173}\n",
      "Epoch 27: loss: 16.0784, train accuracy: 0.8697, valid accuracy:0.8515\n",
      "Start epoch #28, learning rate for this epoch: [4.665599999999999e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:23<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #28, time for this epoch: 143.41901063919067s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.73906514, 0.83797814, 0.70598012, 0.70852175, 0.74463817,\n",
      "       0.44032419]), 0.7472366635458979, 0.8544971773772753, 0.8453168793710459)\n",
      "train: {'mIoU': 0.7799890731767847, 'F1': 0.8752035365882694, 'OA': 0.8693404044860449}\n",
      "{'ImSurf': 0.7885067700436802, 'Building': 0.8872879720194504, 'LowVeg': 0.7241432762488923, 'Tree': 0.7298413241244848, 'Car': 0.7701660234474156, 'Clutter': 0.5064828990448674}\n",
      "val: {'mIoU': 0.7472366635458979, 'F1': 0.8544971773772753, 'OA': 0.8453168793710459}\n",
      "{'ImSurf': 0.7390651352096966, 'Building': 0.8379781424640185, 'LowVeg': 0.7059801216146018, 'Tree': 0.7085217465859929, 'Car': 0.7446381718551797, 'Clutter': 0.440324190187041}\n",
      "Epoch 28: loss: 16.0322, train accuracy: 0.8693, valid accuracy:0.8453\n",
      "Start epoch #29, learning rate for this epoch: [4.665599999999999e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:21<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #29, time for this epoch: 141.87280988693237s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74663192, 0.85171179, 0.70599873, 0.70399501, 0.74524823,\n",
      "       0.42750448]), 0.7507171347497722, 0.8565684794962338, 0.8468222854296593)\n",
      "train: {'mIoU': 0.7810014387416819, 'F1': 0.875791580197847, 'OA': 0.8707854533806826}\n",
      "{'ImSurf': 0.7859429279182039, 'Building': 0.8930629195562345, 'LowVeg': 0.7256775804088796, 'Tree': 0.7326573131782061, 'Car': 0.7676664526468855, 'Clutter': 0.5029702606990061}\n",
      "val: {'mIoU': 0.7507171347497722, 'F1': 0.8565684794962338, 'OA': 0.8468222854296593}\n",
      "{'ImSurf': 0.746631923334294, 'Building': 0.8517117893184037, 'LowVeg': 0.7059987277961588, 'Tree': 0.7039950052172336, 'Car': 0.745248228082771, 'Clutter': 0.4275044832747638}\n",
      "Epoch 29: loss: 16.0453, train accuracy: 0.8708, valid accuracy:0.8468\n",
      "Start epoch #30, learning rate for this epoch: [2.7993599999999992e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:21<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #30, time for this epoch: 141.82536435127258s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74364947, 0.8437467 , 0.71159837, 0.71219826, 0.74223052,\n",
      "       0.43445892]), 0.7506846637805612, 0.8567383187146783, 0.8479919104976612)\n",
      "train: {'mIoU': 0.7836503023463044, 'F1': 0.8774447430669557, 'OA': 0.8717721242171067}\n",
      "{'ImSurf': 0.7918855070037135, 'Building': 0.8936097831087367, 'LowVeg': 0.7249123745011634, 'Tree': 0.7316647360568483, 'Car': 0.7761791110610599, 'Clutter': 0.5089110350648584}\n",
      "val: {'mIoU': 0.7506846637805612, 'F1': 0.8567383187146783, 'OA': 0.8479919104976612}\n",
      "{'ImSurf': 0.7436494707470552, 'Building': 0.8437467025504495, 'LowVeg': 0.7115983717305959, 'Tree': 0.712198258471833, 'Car': 0.7422305154028719, 'Clutter': 0.4344589248690473}\n",
      "Epoch 30: loss: 15.8997, train accuracy: 0.8718, valid accuracy:0.8480\n",
      "Start epoch #31, learning rate for this epoch: [2.7993599999999992e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:23<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #31, time for this epoch: 143.19847512245178s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74647274, 0.85400836, 0.71084376, 0.70062525, 0.74200816,\n",
      "       0.43642218]), 0.7507916554909473, 0.856587757781029, 0.8478032952149137)\n",
      "train: {'mIoU': 0.7856809204945433, 'F1': 0.878881751709109, 'OA': 0.8743046766672379}\n",
      "{'ImSurf': 0.794084656117193, 'Building': 0.8894512532531266, 'LowVeg': 0.7311591881362669, 'Tree': 0.7397069099125129, 'Car': 0.7740025950536171, 'Clutter': 0.5378789768554616}\n",
      "val: {'mIoU': 0.7507916554909473, 'F1': 0.856587757781029, 'OA': 0.8478032952149137}\n",
      "{'ImSurf': 0.7464727395676155, 'Building': 0.8540083646291202, 'LowVeg': 0.7108437640706153, 'Tree': 0.7006252479145674, 'Car': 0.7420081612728173, 'Clutter': 0.43642217779286796}\n",
      "Epoch 31: loss: 15.6707, train accuracy: 0.8743, valid accuracy:0.8478\n",
      "Start epoch #32, learning rate for this epoch: [2.7993599999999992e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:21<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #32, time for this epoch: 141.98484444618225s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74637421, 0.86549913, 0.70790823, 0.70349148, 0.76025271,\n",
      "       0.44229055]), 0.7567051526683543, 0.8602776109735825, 0.8503237667480817)\n",
      "train: {'mIoU': 0.7840144799322603, 'F1': 0.8777171926327207, 'OA': 0.8727162740169427}\n",
      "{'ImSurf': 0.7916973876721354, 'Building': 0.8920396052575257, 'LowVeg': 0.7281718515307167, 'Tree': 0.7306766490149722, 'Car': 0.7774869061859514, 'Clutter': 0.5217304887908069}\n",
      "val: {'mIoU': 0.7567051526683543, 'F1': 0.8602776109735825, 'OA': 0.8503237667480817}\n",
      "{'ImSurf': 0.7463742095266238, 'Building': 0.8654991335651284, 'LowVeg': 0.707908228457229, 'Tree': 0.7034914794458432, 'Car': 0.7602527123469468, 'Clutter': 0.44229055475791285}\n",
      "Epoch 32: loss: 15.8677, train accuracy: 0.8727, valid accuracy:0.8503\n",
      "Start epoch #33, learning rate for this epoch: [2.7993599999999992e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:30<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #33, time for this epoch: 150.7429976463318s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74448   , 0.85252743, 0.70565832, 0.70403393, 0.7453354 ,\n",
      "       0.41527129]), 0.7504070158011343, 0.8563511030866906, 0.8465743218919652)\n",
      "train: {'mIoU': 0.7869364735868942, 'F1': 0.879527732345899, 'OA': 0.8753251632054647}\n",
      "{'ImSurf': 0.7971524464560604, 'Building': 0.8966690092089917, 'LowVeg': 0.7285057457796039, 'Tree': 0.7371751533271862, 'Car': 0.7751800131626283, 'Clutter': 0.5317838920029156}\n",
      "val: {'mIoU': 0.7504070158011343, 'F1': 0.8563511030866906, 'OA': 0.8465743218919652}\n",
      "{'ImSurf': 0.744479995786194, 'Building': 0.8525274322157596, 'LowVeg': 0.7056583215765528, 'Tree': 0.7040339281178615, 'Car': 0.7453354013093038, 'Clutter': 0.4152712874304844}\n",
      "Epoch 33: loss: 15.6467, train accuracy: 0.8753, valid accuracy:0.8466\n",
      "Start epoch #34, learning rate for this epoch: [1.6796159999999994e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:23<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #34, time for this epoch: 143.61338424682617s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74626669, 0.8551077 , 0.70110682, 0.70916597, 0.75368278,\n",
      "       0.46480536]), 0.7530659896107952, 0.8580542853725737, 0.8489642338365936)\n",
      "train: {'mIoU': 0.7863660773632505, 'F1': 0.8792457145314005, 'OA': 0.8751990886834952}\n",
      "{'ImSurf': 0.7938808061820856, 'Building': 0.8946986434767797, 'LowVeg': 0.7336118121477342, 'Tree': 0.7385533032683749, 'Car': 0.7710858217412783, 'Clutter': 0.5314491276588422}\n",
      "val: {'mIoU': 0.7530659896107952, 'F1': 0.8580542853725737, 'OA': 0.8489642338365936}\n",
      "{'ImSurf': 0.74626668662548, 'Building': 0.8551076993541171, 'LowVeg': 0.7011068178436789, 'Tree': 0.7091659658511226, 'Car': 0.7536827783795775, 'Clutter': 0.46480536449331483}\n",
      "Epoch 34: loss: 15.7161, train accuracy: 0.8752, valid accuracy:0.8490\n",
      "Start epoch #35, learning rate for this epoch: [1.6796159999999994e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:26<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #35, time for this epoch: 146.57439827919006s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74339635, 0.85847341, 0.70802594, 0.70571759, 0.73679646,\n",
      "       0.45481964]), 0.7504819492883275, 0.8563294010072049, 0.8501705873466101)\n",
      "train: {'mIoU': 0.7884512389144802, 'F1': 0.8805082276443681, 'OA': 0.8761545817057291}\n",
      "{'ImSurf': 0.7958801320108191, 'Building': 0.8979230546205795, 'LowVeg': 0.7342487290248506, 'Tree': 0.7368434163673038, 'Car': 0.7773608625488483, 'Clutter': 0.5372426944350769}\n",
      "val: {'mIoU': 0.7504819492883275, 'F1': 0.8563294010072049, 'OA': 0.8501705873466101}\n",
      "{'ImSurf': 0.7433963481828658, 'Building': 0.8584734116088041, 'LowVeg': 0.7080259363863012, 'Tree': 0.7057175933313862, 'Car': 0.7367964569322807, 'Clutter': 0.4548196438267196}\n",
      "Epoch 35: loss: 15.5534, train accuracy: 0.8762, valid accuracy:0.8502\n",
      "Start epoch #36, learning rate for this epoch: [1.6796159999999994e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:23<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #36, time for this epoch: 143.37231612205505s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74229398, 0.8510804 , 0.71311408, 0.7010684 , 0.75728   ,\n",
      "       0.41513825]), 0.7529673706322171, 0.8580638381178958, 0.8479686553582644)\n",
      "train: {'mIoU': 0.7915871928174305, 'F1': 0.8824759398648944, 'OA': 0.878197342921526}\n",
      "{'ImSurf': 0.8002460037760436, 'Building': 0.9011273459956961, 'LowVeg': 0.7387480371919992, 'Tree': 0.7400459021204675, 'Car': 0.777768675002946, 'Clutter': 0.5259822745754886}\n",
      "val: {'mIoU': 0.7529673706322171, 'F1': 0.8580638381178958, 'OA': 0.8479686553582644}\n",
      "{'ImSurf': 0.7422939829668318, 'Building': 0.8510803980132127, 'LowVeg': 0.7131140818842117, 'Tree': 0.7010683950811006, 'Car': 0.7572799952157285, 'Clutter': 0.41513825416786765}\n",
      "Epoch 36: loss: 15.4630, train accuracy: 0.8782, valid accuracy:0.8480\n",
      "Start epoch #37, learning rate for this epoch: [1.6796159999999994e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:25<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #37, time for this epoch: 145.92391729354858s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.75321396, 0.86181305, 0.71056615, 0.70065793, 0.74169564,\n",
      "       0.45144377]), 0.7535893462014466, 0.8582981929749851, 0.8511383757690516)\n",
      "train: {'mIoU': 0.7865258740714217, 'F1': 0.8793301592748183, 'OA': 0.8758520254722009}\n",
      "{'ImSurf': 0.7983245522590066, 'Building': 0.8945238560343527, 'LowVeg': 0.7329549019934924, 'Tree': 0.7384821691530825, 'Car': 0.7683438909171745, 'Clutter': 0.5296998867275141}\n",
      "val: {'mIoU': 0.7535893462014466, 'F1': 0.8582981929749851, 'OA': 0.8511383757690516}\n",
      "{'ImSurf': 0.7532139638051565, 'Building': 0.8618130493123456, 'LowVeg': 0.7105661508441432, 'Tree': 0.7006579293623458, 'Car': 0.7416956376832415, 'Clutter': 0.45144377402956265}\n",
      "Epoch 37: loss: 15.6431, train accuracy: 0.8759, valid accuracy:0.8511\n",
      "Start epoch #38, learning rate for this epoch: [1.0077695999999996e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #38, time for this epoch: 144.70488214492798s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:11<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.75194477, 0.85711836, 0.7083816 , 0.71358001, 0.75154204,\n",
      "       0.43349818]), 0.7565133570968918, 0.8603554946616795, 0.8500588465661173)\n",
      "train: {'mIoU': 0.7887184640262205, 'F1': 0.8807140660055042, 'OA': 0.8764003148445716}\n",
      "{'ImSurf': 0.7996179388990197, 'Building': 0.8960508012440772, 'LowVeg': 0.7365628504708628, 'Tree': 0.7376900486362314, 'Car': 0.7736706808809114, 'Clutter': 0.5310670991255612}\n",
      "val: {'mIoU': 0.7565133570968918, 'F1': 0.8603554946616795, 'OA': 0.8500588465661173}\n",
      "{'ImSurf': 0.7519447704394077, 'Building': 0.8571183578608138, 'LowVeg': 0.70838159907136, 'Tree': 0.7135800144972455, 'Car': 0.7515420436156323, 'Clutter': 0.4334981805048482}\n",
      "Epoch 38: loss: 15.5837, train accuracy: 0.8764, valid accuracy:0.8501\n",
      "Start epoch #39, learning rate for this epoch: [1.0077695999999996e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:23<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #39, time for this epoch: 143.08922123908997s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:12<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.74476496, 0.85755754, 0.70726967, 0.70555443, 0.75082271,\n",
      "       0.45759052]), 0.7531938618161227, 0.8581221422084369, 0.8488146582697246)\n",
      "train: {'mIoU': 0.7897679358310787, 'F1': 0.8813953835629352, 'OA': 0.8775718059295263}\n",
      "{'ImSurf': 0.8015007104570863, 'Building': 0.8957850335396774, 'LowVeg': 0.7359805224695358, 'Tree': 0.7417244179187341, 'Car': 0.7738489947703604, 'Clutter': 0.5272988605215414}\n",
      "val: {'mIoU': 0.7531938618161227, 'F1': 0.8581221422084369, 'OA': 0.8488146582697246}\n",
      "{'ImSurf': 0.7447649640333002, 'Building': 0.857557540076613, 'LowVeg': 0.7072696697934135, 'Tree': 0.705554429920706, 'Car': 0.7508227052565809, 'Clutter': 0.4575905213037916}\n",
      "Epoch 39: loss: 15.5396, train accuracy: 0.8776, valid accuracy:0.8488\n",
      "Start epoch #40, learning rate for this epoch: [1.0077695999999996e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [02:24<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done epoch #40, time for this epoch: 144.61492228507996s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4/88 [00:00<00:16,  4.98it/s]Exception in thread Thread-48 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 51, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 307, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/resource_sharer.py\", line 58, in detach\n",
      "    return reduction.recv_handle(conn)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 189, in recv_handle\n",
      "    return recvfds(s, 1)[0]\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/reduction.py\", line 159, in recvfds\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  7%|▋         | 6/88 [00:01<00:16,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "train_loss_array = []\n",
    "test_loss_array = []\n",
    "last_loss = 9999999999999\n",
    "for epoch in range(40):\n",
    "    try:\n",
    "        train_loss_epoch = 0\n",
    "        test_loss_epoch = 0\n",
    "        train_loss_epoch, train_eval_value, test_loss_epoch, eval_value = train(train_loader, \n",
    "                                                  val_loader, \n",
    "                                                  learing_rate_scheduler, epoch, display_step)\n",
    "\n",
    "        if test_loss_epoch < last_loss:\n",
    "            save_model(model, optimizer, checkpoint_path)\n",
    "            last_loss = test_loss_epoch\n",
    "\n",
    "        iou_value = {}\n",
    "        iou_per_class,mIoU,F1,OA=train_eval_value\n",
    "        eval_value_train = {'mIoU': mIoU,\n",
    "                          'F1': F1,\n",
    "                          'OA': OA}                                          \n",
    "        print('train:', eval_value_train)\n",
    "        train_accuracy.append(OA)\n",
    "        wandb.log({'mIoU_train': mIoU,\n",
    "                          'F1_train': F1,\n",
    "                          'OA_train': OA}) \n",
    "\n",
    "        for class_name, iou in zip(CLASSES,iou_per_class):\n",
    "            wandb.log({f\"{class_name}_train_IOU\": iou})\n",
    "            iou_value[class_name] = iou\n",
    "        print(iou_value)\n",
    "\n",
    "        iou_value = {}\n",
    "        iou_per_class,mIoU,F1,OA = eval_value\n",
    "        eval_value_val = {'mIoU': mIoU,\n",
    "                          'F1': F1,\n",
    "                          'OA': OA}                                          \n",
    "        print('val:', eval_value_val)\n",
    "        valid_accuracy.append(OA)\n",
    "        wandb.log({'mIoU_val': mIoU,\n",
    "                          'F1_val': F1,\n",
    "                          'OA_val': OA})\n",
    "        for class_name, iou in zip(CLASSES,iou_per_class):\n",
    "            wandb.log({f\"{class_name}_val_IoU\": iou})\n",
    "            iou_value[class_name] = iou\n",
    "        print(iou_value)\n",
    "\n",
    "        learing_rate_scheduler.step()\n",
    "        train_loss_array.append(train_loss_epoch)\n",
    "        test_loss_array.append(test_loss_epoch)\n",
    "        wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch})\n",
    "        print(\"Epoch {}: loss: {:.4f}, train accuracy: {:.4f}, valid accuracy:{:.4f}\".format(epoch + 1, \n",
    "                                            train_loss_array[-1], train_accuracy[-1], valid_accuracy[-1]))\n",
    "    except:\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1bcb7bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T13:27:47.884955Z",
     "iopub.status.busy": "2023-12-16T13:27:47.884569Z",
     "iopub.status.idle": "2023-12-16T13:27:47.892250Z",
     "shell.execute_reply": "2023-12-16T13:27:47.891354Z"
    },
    "papermill": {
     "duration": 1.211754,
     "end_time": "2023-12-16T13:27:47.894259",
     "exception": false,
     "start_time": "2023-12-16T13:27:46.682505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ca205e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T13:27:50.325252Z",
     "iopub.status.busy": "2023-12-16T13:27:50.324490Z",
     "iopub.status.idle": "2023-12-16T13:27:50.332852Z",
     "shell.execute_reply": "2023-12-16T13:27:50.332000Z"
    },
    "papermill": {
     "duration": 1.26201,
     "end_time": "2023-12-16T13:27:50.334937",
     "exception": false,
     "start_time": "2023-12-16T13:27:49.072927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def img_writer(inp):\n",
    "    (mask,  mask_id, rgb) = inp\n",
    "    if rgb:\n",
    "        mask_name_tif = mask_id + '.png'\n",
    "        mask_tif = label2rgb(mask)\n",
    "        cv2.imwrite(mask_name_tif, mask_tif)\n",
    "    else:\n",
    "        mask_png = mask.astype(np.uint8)\n",
    "        mask_name_png = mask_id + '.png'\n",
    "        cv2.imwrite(mask_name_png, mask_png)\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    arg = parser.add_argument\n",
    "    arg(\"-c\", \"--config_path\", type=Path, required=True, help=\"Path to  config\")\n",
    "    arg(\"-o\", \"--output_path\", type=Path, help=\"Path where to save resulting masks.\", required=True)\n",
    "    arg(\"-t\", \"--tta\", help=\"Test time augmentation.\", default=None, choices=[None, \"d4\", \"lr\"])\n",
    "    arg(\"--rgb\", help=\"whether output rgb images\", action='store_true')\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "256cb5bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T13:27:52.767456Z",
     "iopub.status.busy": "2023-12-16T13:27:52.766783Z",
     "iopub.status.idle": "2023-12-16T13:27:53.065910Z",
     "shell.execute_reply": "2023-12-16T13:27:53.065177Z"
    },
    "papermill": {
     "duration": 1.468738,
     "end_time": "2023-12-16T13:27:53.067839",
     "exception": false,
     "start_time": "2023-12-16T13:27:51.599101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = PotsdamDataset(data_root='/kaggle/input/deep-data-potsdam-vaihingen/Deep_data_segmentation/Split/Vaihingen/Test',\n",
    "                              transform=val_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69715ec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T13:27:55.543021Z",
     "iopub.status.busy": "2023-12-16T13:27:55.542545Z",
     "iopub.status.idle": "2023-12-16T13:28:01.472897Z",
     "shell.execute_reply": "2023-12-16T13:28:01.471332Z"
    },
    "papermill": {
     "duration": 7.209905,
     "end_time": "2023-12-16T13:28:01.475253",
     "exception": false,
     "start_time": "2023-12-16T13:27:54.265348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:05<00:00, 40.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_ImSurf:0.5618505399074194, IOU_ImSurf:0.39067604271898865\n",
      "F1_Building:0.7103269497812126, IOU_Building:0.5507806413886907\n",
      "F1_LowVeg:0.06093045547741564, IOU_LowVeg:0.031422522028428455\n",
      "F1_Tree:0.04499079610776339, IOU_Tree:0.023013086597337244\n",
      "F1_Car:0.2496819635751765, IOU_Car:0.14264948333913852\n",
      "F1_Clutter:0.08056004587906423, IOU_Clutter:0.0419705996564811\n",
      "F1:0.3255561409697975, mIOU:0.2277083552145167, OA:0.4430487450132977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images writing spends: 0.05967283248901367 s\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "model.eval()\n",
    "evaluator = Evaluator(num_class=6)\n",
    "evaluator.reset()\n",
    "with torch.no_grad():\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    results = []\n",
    "    for input in tqdm(test_loader):\n",
    "        # raw_prediction NxCxHxW\n",
    "        raw_predictions = model(input['img'].cuda())\n",
    "\n",
    "        image_ids = input[\"img_id\"]\n",
    "        masks_true = input['gt_semantic_seg']\n",
    "\n",
    "        raw_predictions = nn.Softmax(dim=1)(raw_predictions)\n",
    "        predictions = raw_predictions.argmax(dim=1)\n",
    "\n",
    "        for i in range(raw_predictions.shape[0]):\n",
    "            mask = predictions[i].cpu().numpy()\n",
    "            evaluator.add_batch(pre_image=mask, gt_image=masks_true[i].cpu().numpy())\n",
    "            mask_name = image_ids[i]\n",
    "iou_per_class = evaluator.Intersection_over_Union()\n",
    "f1_per_class = evaluator.F1()\n",
    "OA = evaluator.OA()\n",
    "for class_name, class_iou, class_f1 in zip(CLASSES, iou_per_class, f1_per_class):\n",
    "    print('F1_{}:{}, IOU_{}:{}'.format(class_name, class_f1, class_name, class_iou))\n",
    "print('F1:{}, mIOU:{}, OA:{}'.format(np.nanmean(f1_per_class[:-1]), np.nanmean(iou_per_class[:-1]), OA))\n",
    "t0 = time.time()\n",
    "mpp.Pool(processes=2).map(img_writer, results)\n",
    "t1 = time.time()\n",
    "img_write_time = t1 - t0\n",
    "print('images writing spends: {} s'.format(img_write_time))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4130659,
     "sourceId": 7153471,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4139055,
     "sourceId": 7165240,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4145006,
     "sourceId": 7173542,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4148253,
     "sourceId": 7177819,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30616,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6531.888585,
   "end_time": "2023-12-16T13:28:05.599408",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-16T11:39:13.710823",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
